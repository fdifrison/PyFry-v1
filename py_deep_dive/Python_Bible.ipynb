{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>My Personal Python Bible</h1>\n",
    "\n",
    "by Ing. Giovanni Frison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " last update: 2022-05-09\n"
     ]
    }
   ],
   "source": [
    "from datetime import date\n",
    "print(f' last update: {date.today()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TOC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. [PEP8 naming convention](#PEP8-naming-convention)\n",
    "2. [Everything is an Object](#Everything-is-an-Object)\n",
    "3. [Modules](#Modules)\n",
    "    1. [Some clarifications](#Some-clarifications)\n",
    "    2. [Reload a module](#Reload-a-module)\n",
    "4. [Packages](#Packages)\n",
    "    1. [Package structure](#Package-structure)\n",
    "    2. [Package Namespace PEP 420](#Package-Namespace-PEP-420)\n",
    "4. [Variables and Memory](#Variables-and-Memory)\n",
    "    1. [id function](#id-function)\n",
    "    2. [Reference Counting](#Reference-Counting)\n",
    "    3. [Shared Reference](#Shared-Reference)\n",
    "    4. [Garbage Collection](#Garbage-Collection)\n",
    "    5. [Object Mutability](#Object-Mutability)\n",
    "    6. [Variable Equality](#Variable-Equality)\n",
    "5. [Built-in methods](#Built-in-methods)\n",
    "   1. [isinstance(object, class)](#isinstance(object,-class))\n",
    "   2. [issubclass(object, class)](#issubclass(object,-class))  \n",
    "16. [Numeric Types](#Numeric-Types)\n",
    "    1.  [Integers](#Integers)\n",
    "        1.  [Operations](#Operations)\n",
    "        2.  [Base](#Base)\n",
    "    2.  [Rational Numbers](#Rational-Numbers)\n",
    "    3.  [Floats (Real Numbers)](#floats-real-numbers)\n",
    "        1.  [equality](#equality)\n",
    "    4.  [Booleans PEP 285](#Booleans-PEP-285)\n",
    "        1.  [Booleans operators](#Booleans-operators)\n",
    "        2.  [Short-Circuiting](#Short-Circuiting)\n",
    "6. [Iterable and Iterators](#Iterable-and-Iterators)\n",
    "    1. [Consume iterators manually](#Consume-iterators-manually)\n",
    "    2. [Lazy Iterables](#Lazy-Iterables)\n",
    "    3. [iter() method](#iter()-method)\n",
    "        1. [iter() with callables](#iter()-with-callables)\n",
    "    4. [Delegating Iterators](#Delegating-Iterators)\n",
    "    5. [Reversed Iteration](#Reversed-Iteration)\n",
    "    6. [Caveats: using iterators as function arguments](#Caveats:-using-iterators-as-function-arguments)\n",
    "7. [Generators](#Generators)\n",
    "   1. [Iterables from generators](#Iterables-from-generators)\n",
    "   2. [Generator expressions](#Generator-expressions)\n",
    "   3. [Yield from](#Yield-from)\n",
    "8. [Sequence Type](#Sequence-Type)\n",
    "   1. [Mutating sequence](#Mutating-sequence)\n",
    "      1. [in-place concatenation and repetition](#in-place-concatenation-and-repetition)\n",
    "      2. [Mutation by assignment](#Mutation-by-assignment)\n",
    "      3. [Never return a mutated object](#Never-return-a-mutated-object)\n",
    "   2. [Copying Sequences](#Copying-Sequences)\n",
    "      1. [Shallow copies](#Shallow-copies)\n",
    "      2. [Deep Copies](#Deep-Copies)\n",
    "   3. [Slicing](#Slicing)\n",
    "   4. [Custom Sequences](#Custom-Sequences)\n",
    "      1. [Mutation in custom sequences](#Mutation-in-custom-sequences)\n",
    "   5. [Sorting sequences](#sorting-sequences)\n",
    "   6. [Zero-based Index](#Zero-based-Index)\n",
    "   7. [Application - Polygon](#Application---Polygon)\n",
    "   8. [Lists vs Tuples](#Lists-vs-Tuples)\n",
    "       1. [Copying](#Copying)\n",
    "       2. [Storing Efficiency](#Storing-Efficiency)\n",
    "9.  [Iteration Tools - The itertools module](#Iteration-Tools---The-itertools-module)\n",
    "    1. [Aggregators](#Aggregators)\n",
    "    2. [iSlicing](#iSlicing)\n",
    "    3. [Selecting and Filtering](#Selecting-and-Filtering)\n",
    "    4. [Infinite iterators](#Infinite-iterators)\n",
    "    5. [Chaining and Teeing](#Chaining-and-Teeing)\n",
    "    6. [Mapping and Accumulation](#Mapping-and-Accumulation)\n",
    "10. [Strings](#Strings)\n",
    "    1. [Common methods](#Common-methods) \n",
    "11. [Lists](#Lists)\n",
    "    1. [List comprehension](#List-comprehension)\n",
    "12. [Tuples](#Tuples)\n",
    "   9. [Named Tuples](#Named-Tuples)\n",
    "      1. [Introspection](#Introspection)\n",
    "      2. [Modify and Extending](#Modify-and-Extending)\n",
    "      3. [Docstring](#Docstring)\n",
    "      4. [Defaults values](#Defaults-values)\n",
    "13. [Dictionaries](#Dictionaries)\n",
    "14. [Unpacking iterables](#Unpacking-iterables)\n",
    "   10. [Unpacking with *](#Unpacking-with-*)\n",
    "   11. [Nested unpacking](#Nested-unpacking)\n",
    "15. [Loops](#Loops)\n",
    "   12. [While loop](#While-loop)\n",
    "   13. [Try statement](#Try-statement)\n",
    "16. [Functions](#Functions)\n",
    "    1.  [Docstrings and annotations - PEP 257](#Docstrings-and-annotations---PEP-257)\n",
    "    2.  [lambda expression](#lambda-expression)\n",
    "    3.  [Function Introspection](#Function-Introspection)\n",
    "    4.  [\\*args and **kwargs](#\\*args-and-**kwargs)\n",
    "    5.  [Parameters default](#Parameters-default)\n",
    "    6.  [Map, Filter and Zip functions](#Map-Filter-and-Zip-functions)\n",
    "    7.  [Reducing Functions](#Reducing-Functions)\n",
    "    8.  [Partial functions](#Partial-functions)\n",
    "    9.  [The operator module](#The-operator-module)\n",
    "17. [Classes](#Classes)\n",
    "    1. [Getters and Setters](#Getters-and-Setters)\n",
    "    2. [Overload methods](#Overload-methods)\n",
    "    3. [\\_\\_str\\_\\_ method](#\\_\\_str\\_\\_-method)\n",
    "    4. [\\_\\_repr\\_\\_ method](#\\_\\_str\\_\\_-method)\n",
    "    5. [\\_\\_eq\\_\\_ method](#\\_\\_str\\_\\_-method)\n",
    "18. [Scopes and Namespaces](#Scopes-and-Namespaces)\n",
    "    1.  [Masking](#Masking)\n",
    "    2.  [Nonlocal scope](#Nonlocal-scope)\n",
    "19. [Closure](#Closure)\n",
    "    1.  [Shared extend scope](#Shared-extend-scope)\n",
    "    2.  [Nested Closure](#Nested-Closure)\n",
    "    3.  [Application](#Application)\n",
    "20. [Decorators](#Decorators)\n",
    "    1.  [Multiple decorators](#Multiple-decorators)\n",
    "    2.  [Memoization](#Memoization)\n",
    "    3.  [Parametrized decorators](#Parametrized-decorators)\n",
    "    4.  [Decorator class](#Decorator-class)\n",
    "    5.  [Monkey Patching and Decorating classes](#Monkey-Patching-and-Decorating-classes)\n",
    "    6.  [Single Dispatch Generic Functions](#Single-Dispatch-Generic-Functions)\n",
    "        1.  [Application - Htmlizer](#Application---Htmlizer)\n",
    "21. [Python optimizations](#Python-optimizations)\n",
    "    1.  [Interning](#Interning)\n",
    "    2.  [Peephole](#Peephole)\n",
    "22. [Common Modules](#Common-Modules)\n",
    "    1. [string](#string)\n",
    "    2. [functools](#functools)\n",
    "    3. [itertools](#itertools)\n",
    "    4. [collections](#collections)\n",
    "    5. [random](#random)\n",
    "    6. [timeit](#timeit)\n",
    "    7. [argparser](#argparser)\n",
    "23. [Tips and tricks](#Tips-and-tricks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PEP8 naming convention\n",
    "---\n",
    "\n",
    "- `packages`: short lowercase and without underscore es. `utilities`\n",
    "- `modules`: short lowercase and with underscore es. `db_utils`\n",
    "- `classes`: first letter of each word are uppercase, no spaces and no underscore es. `MyClass`\n",
    "- `functions` lowercase and with underscore es. `open_account`\n",
    "- `variables` lowercase and with underscore es. `account_id`\n",
    "- `constants` all uppercase with underscore es `MIN_VAL`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "back to [TOC](#TOC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Everything is an Object\n",
    "---\n",
    "In python everything is an object. Functions for example, inherit from the built-in function class; the same happen for classes which inherit from class function. This implies that every objects has a memory address (yes, even function and classes). In the same way every object che by assigned to a variable, passed as argument to a function or returned by a function. We can look at the object type of any variable with the `type` built-in function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "back to [TOC](#TOC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modules\n",
    "---\n",
    "\n",
    "First lest define what is the `Namespace`: essentially it is a dictionary that contains all the reference in memory that are currently loaded into the python interpreter. It can be access with two different keywords, `globals()` to access the global namespace, and `locals()` to access the local namespace of, let's say, a function.\n",
    "\n",
    "Like everything in python, also modules are object of the type module. When a module is imported, it get cached into memory (not in the namespace), and its memory reference is reported in the global namespace. \n",
    "Due to this, if we were to import the same module from two different scripts, the memory address would be the same across the scripts (we can think about it as a singleton object). We can look at the OS cache using the `sys.modules` which is a dictionary aswell.\n",
    "\n",
    "The importing is done at runtime (i.e. while the python interpreter is already running) and not at compilation time like in C for example. The way python retrieve its modules is quite complex but to help understand it we can make use of the `sys` module which has some useful functionalities. For example we can look at where the current python execution ans the relative C binaries are with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/usr', '/usr')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.prefix, sys.exec_prefix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can see we are using the active virtual environment where both the installation and the C binaries are locate. As a matter of fact, modifying the `prefix` is the way python use to activate/deactivate a virtual environment.\n",
    "\n",
    "But where python looks for import modules? There is a list of directory where python is looking, and these can be inspect with `sys.path`. If a module import fails, we can check if it is actually stored in one of the directory listed in path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/pyfry/Desktop/Python_Projects/py_deep_dive',\n",
       " '/usr/lib/python38.zip',\n",
       " '/usr/lib/python3.8',\n",
       " '/usr/lib/python3.8/lib-dynload',\n",
       " '',\n",
       " '/home/pyfry/.local/lib/python3.8/site-packages',\n",
       " '/usr/local/lib/python3.8/dist-packages',\n",
       " '/usr/lib/python3/dist-packages',\n",
       " '/home/pyfry/.local/lib/python3.8/site-packages/IPython/extensions',\n",
       " '/home/pyfry/.ipython']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The operations that python does during the import of a modules are:\n",
    "* checking if already exist in cache -> `sys.modules`\n",
    "* if not, create a new modules type object -> `types.ModuleType`\n",
    "* load the source code from file\n",
    "* add the entry to sys.modules\n",
    "* compile adn execute the source code -> N.B. the code in the imported module is executed!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, the importing of a module seems to be quite straightforward, what is more complicated is how python actually find the module we want to load. We can simply saying that there are 3 constructure at play:\n",
    "* finders\n",
    "* loaders\n",
    "* finder + loaders == importer\n",
    "\n",
    "First the `finders` are question wheter or not they know anything about the module we are trying to import; the list of the available finders can be found like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[_frozen_importlib.BuiltinImporter,\n",
       " _frozen_importlib.FrozenImporter,\n",
       " _frozen_importlib_external.PathFinder,\n",
       " <six._SixMetaPathImporter at 0x7f62cf3bb550>,\n",
       " <pkg_resources.extern.VendorImporter at 0x7f62ce160ee0>,\n",
       " <pkg_resources._vendor.six._SixMetaPathImporter at 0x7f62ce17c2b0>]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.meta_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If one of the importer know the module it will built a `Modulespec` and tell the `loader` to load it. (es. the module math, since is a builti-in module, is found by the `BuiltinImporter` finder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModuleSpec(name='math', loader=<class '_frozen_importlib.BuiltinImporter'>, origin='built-in')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "math.__spec__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can find if a module is in the python path and look at its specs at the same time with the built-in module `importlib` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModuleSpec(name='math', loader=<class '_frozen_importlib.BuiltinImporter'>, origin='built-in')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "importlib.util.find_spec('math')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if `module_name` exist in `sys.path`, then its spec will be returned, if not we can solve the issue appending to the path list the directory where the module is found:\n",
    "\n",
    "```py\n",
    "import sys\n",
    "sys.path.append('module_path')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If this has to become systematic, for example in a project where many paths have to added, the best way to procede is to compile a `.pth` file. For more information look at [https://docs.python.org/3/library/site.html](#https://docs.python.org/3/library/site.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some clarifications\n",
    "We have seen that when a module is imported for the first time, if founded in `sys.path`, its address is added to `sys.module`. Instead, what goes inside the namespace `globals()` depends on how we import the module itself, wheter with an alias or not. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "# in this way the module math is loaded into sys.module and the name `math` is added to the namespace globals()\n",
    "# both the `math` names point to the same address\n",
    "\n",
    "import math as math_alias\n",
    "\n",
    "# in this way the module math is loaded into sys.module but name `math` is not added to the namespace globals()\n",
    "# instead we found the name `math_alias` which point to the same address associated to `math` in sys.module\n",
    "\n",
    "from math import sqrt\n",
    "\n",
    "# in this way the module math is loaded into sys.module but in the namespace globals() we found only `sqrt`\n",
    "# that points to the function `math.sqrt`\n",
    "\n",
    "from math import *\n",
    "# in this way the module math is loaded into sys.module and the name of every function inside the math module is added to the namespace globals()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N.B. if a name is already present in the namespace and we import something that has the same name, it gets overwritten. This is why it is not recommended to use the `import *` unless we are fully aware of every name we are importing and that there is no conflict between different module's names.\n",
    "\n",
    "N.B.B some things that using an explicit import of a function in a module like `from math import sqrt` is more lightweight; this is essentially not true because the entire math module is loaded in the `sys.module`, the only thing that change is that only the mane `sqrt` is added to the namespace. There is a very small advantage in calling the function because `sqrt(2)` has one less dictionary look-up that `math.sqrt(2)`, but since a dict-lookup is super fast the difference in efficiency is very very small. Therefore, in this case, do things for READABILITY and not EFFICIENCY."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reload a module\n",
    "If, for some reason, we want to reload a module, it is not sufficient to repeat the `import` statement, because the module name is already in the `sys.module`, and when the loader finds it it will skips its reloading. Neither using `del module_name` is enough because we are only deleting the name reference from the namespace. What we need to do is to delete the memory reference in the `sys.module` dictionary: `del sys.module['module_name']` . Now if we re-import the module, we are creating a new object, with a new `id`.\n",
    "\n",
    "As an alternative, if we want to reload the module without destroy and recreate the module object, we can use the `importlib.reload(module_name)` function, which will reload the module keeping the same memory id both for the `sys.module` and the namespace. However, care must be taken when reloading modules, for example, if we are loading only a specific function of a module to the namespace, let's say `from math import sqrt` we can directly reload the module since we don't have the name `math` in the namespace, but we'll have to refer to the sys.module reference -> `imporlib.reload(sys.module[math])`. However, even if `math` has been now reloaded, the same is not happened for the `sqrt` function. To do taht we would have needed to do something like `sqrt = sys.module[math].sqrt`. So be aware! reloading is not a safe process, isn't something we want to do in a production environment!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From more references on modules and module import look at :ù\n",
    "* `PEP 302`\n",
    "* [https://docs.python.org/3/tutorial/modules.html](#https://docs.python.org/3/tutorial/modules.html)\n",
    "* [https://docs.python.org/3/reference/import.html](#https://docs.python.org/3/reference/import.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "back to [TOC](#TOC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Packages\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Packages are a collection of modules and possibly sub-packages that usually have some kind of specialized scope. The substantial difference that can tell us if a module is a package is the presence of a non-empty `__path__` attribute.\n",
    "\n",
    "\n",
    "The 99% of the packages are file-based, therefore structured into directories in the file system. In particular we have that the `directory name` became the `package-name` and the directory needs to contain the code somewhere (since a package is also a module but not vice-versa). In fact, the code goes inside the `__init__.py` file inside the directory, and the pair `directory + __ini__.py` compose a `module`. Substantially, when python finds inside a folder a `__init__.py` file it knows that it is looking at a `package` and not a standard directory. If not, python create an `implicit namespace package` that allow us to navigate trough folders inside the package itself.\n",
    "\n",
    "Now lets look at a typical app folder structure containing modules, package and sub-packages:\n",
    "\n",
    "```\n",
    "app/\n",
    "\n",
    "    module_1.py\n",
    "\n",
    "    pack_1/\n",
    "        `__init__.py`\n",
    "        module_1_a.py\n",
    "        \n",
    "        pack_1_1/\n",
    "            `__init__.py`\n",
    "            module_1_1_a.py   \n",
    "```\n",
    "\n",
    "Imagine we are executing our python interpreter inside the `app` folder. We can now simply say:\n",
    "* `import module_1` : import whats inside module_1.py. If we try to look at `module_1.__path__` we will find that it is empty `''` since module_1 is a module and not a package;\n",
    "* `import pack_1` : import the package `pack1` and loads what inside the `__init__.py`. Now the `pack1.__path__` is not empty since pack1 is a package. Also, python has added `pack1` has been added to both the `sys.modules` and `globals()` (namespace)\n",
    "* `import pack_1_1`: result in an ERROR since the python finder can't navigate up to this package; instead we need to:\n",
    "  * `import pack_1.pack_1_1` to be able to access the nested package. N.B. now `pack_1.pack_1_1` is stored inside `sys.modules` but not in `globals()` where only the root package is stored (`pack_1`); this because we are anyway always gonna refer it as `pack_1.pack_1_1` in our code.\n",
    "  * `from pack_1 import pack_1_1`: in this way we are storing `pack_1_1` in `globals()` but it is only a placeholder since it is actually pointing to the same objects as `pack_1.pack_1_1` (the `id(pack_1_1 == id(sys.modules['pack_1.pack_1_1']`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Package structure\n",
    "\n",
    "When creating a package we need to keep in mind two quite opposite point of view: the `developer` of the package, which needs a good breakdown of the package's functionality to have a better modularity, better debugging, reading etc.. and the `user` which instead only needs to access the functionality coded into the package itself. Therefore, care is needed when structuring the package, and a good use of the `__init__.py` files has a key role. \n",
    "\n",
    "Looking at the previous dummy example, if the user need to access something inside module_1_1_a.py, the import would be something like `import pack_1.pack_1_1.module_1_1_a` i.e. something very tedious and inefficient. If instead the `__init__.py` inside `pack_1` contains directly something like `from pack_1_1 import *`, the user would be able to access everything just doing `import pack_1` because when the package is imported also the `__init__.py` is executed and added to the namespace. \n",
    "\n",
    "However, more then often, using a `*` import is something that we want to avoid, since inside a package there will be many functions/classes that are needed only by the developer and not the user (it might be even 'dangerous' if the user is able to access them). To avoid this there are essentially two methods:\n",
    "\n",
    "* name the 'private' (developer side) functions with an underscore in front (es. `def _func_only_for_dev()`) since the `*` import will avoid those\n",
    "* specify inside each module the list -> `__all__` = ['names_i_want_to_export_from_a_module'], i.e. the list of all the objects we want to be imported with `*` import"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Package Namespace PEP 420\n",
    "Packages Namespace are essentially packages without a `__init__.py` file. They have the advantage that can be spread wherever in the file system (even in a zip file) but the import of sub-modules/packages can't be flatten (we don't have a `__init__.py` to leverage)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "back to [TOC](#TOC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variables and Memory\n",
    "---\n",
    "When a variable is created, what python is doing under the hood is to link the variable name to the memory slot (slots) which contains the element assign to the variable. Therefore the name is nothing more than a reference to the memory slot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `id` function\n",
    "`id` is the function that returns the memory address of a variable in base-10 ( can be converted with `hex` to see the hexadecimal representation)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference Counting\n",
    "Reference counting is a process carried out by the python memory manager internally. Each time we create a new variable, we are creating a reference to a memory slot. If we create a new variable that is equal to an existing one, we are adding a reference to the same memory slot (which now has a reference count equal to two)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sys.refcount returns: 3\n",
      "ctypes returns: 2\n"
     ]
    }
   ],
   "source": [
    "import ctypes\n",
    "import sys\n",
    "\n",
    "my_var_1 = list() # my_var is pointing to the memory slot id(my_var)\n",
    "\n",
    "other_var = my_var_1  # other var is pointing to the same memory slot of my_var\n",
    "# at this point, the ref count of id(my_var) is equal to 2\n",
    "\n",
    "print('sys.refcount returns:' , sys.getrefcount(my_var_1))\n",
    "# return the ref count of the variable + 1 far the call of sys itself\n",
    "\n",
    "print('ctypes returns:' , ctypes.c_long.from_address(id(my_var_1)).value)\n",
    "# is a lower level way to find the ref count of a memory slot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shared Reference\n",
    "When python variables share memory references?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 10, True, True)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = 10\n",
    "b = a\n",
    "# b is not copying the content of a, it is pointing to the same memory address\n",
    "\n",
    "a, b, a == b, a is b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 10, True, True)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "a = 10\n",
    "b = 10\n",
    "# since the number 10 is immutable, both a and b are pointing to the same memory address\n",
    "\n",
    "a, b, a == b, a is b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([1, 2, 3, 4], [1, 2, 3, 4], True, True)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "a = [1,2,3]\n",
    "b = a\n",
    "b.append(4)\n",
    "# now both b and a are equal to [1,2,3,4] since a list is mutable object and appending an element modify only its internal state with the same memory address\n",
    "\n",
    "a, b, a == b, a is b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([1, 2, 3], [1, 2, 3], True, False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "a = [1,2,3]\n",
    "b = [1,2,3]\n",
    "# in this case python doesn't create shared references, so a and b are pointing to different objects, this to prevent that modifying b affects also a\n",
    "\n",
    "a, b, a == b, a is b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N.b. There will be always a shared reference to `None` object, created automatically by python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Garbage Collection\n",
    "It is the way python use to avoid memory leaks such that generated by circular references (objects pointing one to the other). Garbage collection can be controlled using the `gc` method. It can be turned off (only if we are super-sure that there are not circular reference in the code, in order to improve performance). The gc runs periodically on its own but can also be called manually to program a specific cleanup of the code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Object Mutability\n",
    "Changing the data inside an object is called `modifying the internal state` since the memory address is not changed but only its content (es. appending an element to a list). So we can distinguish between `Mutable` and `Immutable` object depending on the possibility of changing the internal state.\n",
    "\n",
    "`Immutable objects:`\n",
    "\n",
    "- Numbers\n",
    "- Strings\n",
    "- Tuples (if contains mutable elements, es. lists, those remain mutable)\n",
    "- Frozen Sets\n",
    "- User_Defined Classes (if so defined)\n",
    "\n",
    "`Mutable objects:`\n",
    "\n",
    "- Lists\n",
    "- Sets\n",
    "- Dictionaries\n",
    "- User_Defined Classes (if so defined)\n",
    "\n",
    "Care must be taken when we talk about immutability of an object that is given to a function as an argument. We have to distinguish between the `module scope` and the `function scope`.\n",
    "When we pass an object to a function we are in reality passing the `reference` of the object itself. So if we are passing to a function an immutable object, say a string, at the beginning both the module scope and the function scope point to the same memory reference, but as soon as the function modify the string (es. concatenating another string), then a new object with a new reference is created. If the object is mutable, say a list, and the function modify the list (es. appending an element), then python doesn't create a new object but simply modify the internal state of the existing memory reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('world', 'helloworld', 140062307458992, 140062307458736)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# IMMUTABLE\n",
    "def process_str(s):\n",
    "  # s has still the same memory reference as my_string\n",
    "  s = 'hello' + s\n",
    "  # now s has been modified, and since it was an immutable object, a new object with a new reference is created.\n",
    "  return s\n",
    "\n",
    "my_string = 'world'\n",
    "\n",
    "my_string, process_str(my_string), id(my_string), id(process_str(my_string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([1, 2, 3, 5, 5], [1, 2, 3, 5, 5], 140062307000000, 140062307000000)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MUTABLE\n",
    "def process_lst(lst):\n",
    "  # lst has the same memory reference as my_list\n",
    "  lst.append(5)\n",
    "  # since lst is a mutable object, only the internal state is changed but the memory reference is still the same.\n",
    "  return lst\n",
    "\n",
    "my_list = [1,2,3]\n",
    "\n",
    "my_list, process_lst(my_list), id(my_list), id(process_lst(my_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variable Equality\n",
    "There are two ways to verify the equality of two variables in python: the `is` and the `==` operators, respectively the identity and equality operators. While the identity operator compares the memory reference of two objects, the equality operator compares their internal state (data). Their negation are `is not` and `!=`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "a = 10\n",
    "b = a\n",
    "print(a is b) # True since the memory address is the same (int are immutable objects)\n",
    "print(a == b) # True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "a = 500\n",
    "b = 500\n",
    "\n",
    "print(a is b) # False, preloaded integers are in the range [-5, 256] see Interning\n",
    "print(a == b) # True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "a = [1,2,3]\n",
    "b = [1,2,3]\n",
    "\n",
    "print(a is b) # False, different memory address\n",
    "print(a == b) # True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "a = 'hello'\n",
    "b = 'hello'\n",
    "\n",
    "print(a is b) # True, but not always! only if strings are stored as Singleton\n",
    "print(a == b) # True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "a = 10.0\n",
    "b = 10\n",
    "\n",
    "print(a is b) # False, float and int are different objects\n",
    "print(a == b) # True, python recognize the have the same value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "back to [TOC](#TOC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Built-in methods\n",
    "---\n",
    "\n",
    "## `isinstance(object, class)`\n",
    "Return `True` if an object is an instance of a particular class, `False` otherwise.\n",
    "\n",
    "## `issubclass(subclass, class)`\n",
    "Return `True` if class inherits from another upper class, `False` otherwise.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "back to [TOC](#TOC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Numeric Types\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integers\n",
    "Integer are represented internally using base-2 digits (binary representation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "# es. binary representation of 19\n",
    "\n",
    " 0   0   0   1   0   0   1   1 \n",
    "--- --- --- --- --- --- --- ---   -> max num of bits = 8\n",
    "2^7 2^6 2^5 2^4 2^3 2^2 2^1 2^0\n",
    "\n",
    "1x2^4 + 0x2^3 + 0x2^2 + 1*2^1 + 1*2^0 = 16 + 2 + 1 = 19\n",
    "\n",
    "(10011)base_2 = (19)base_10\n",
    "\n",
    "To represent the number 19 are required 5 digits, hence 5 bits.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But which is the largest number we can store depending on the number of bits we want to store? It depends whether or not we care about negative values, since in order to store the sign we have to allocate one bit.\n",
    "The general formula is:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "```py\n",
    "max_unsigned_digit = 2^n -1 # where n is the number of bits\n",
    "max_signed_digits = [-2^(n-1), 2^(n-1)-1]\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Side-Note: a 32 bit Operative system can store 2^32 unsigned integers (roughly 4Gb) and this limits also the number of memory address that can be stored at the same time. This is why having more than 4Gb of ram on a 32 bit OS is essentially useless since the machine can't store more than 4 Gb at the same time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Operations\n",
    "How mod `//` (floor division) and div `%` (modulo) operators works in python? mod returns the floor division (rounded to the smaller integer) while div return the remainder. They have to satisfy the following equation:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "```py\n",
    "n = d * (n // d) + (n % d) # where n is the numerator and d is the denominator\n",
    "\n",
    "#n.b. the `floor` of a real number `a` is the largest integer `<= a` \n",
    "floor(3.14) = 3\n",
    "floor(-3.1) = 3\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base\n",
    "We can create an `int` object by calling the `int()` constructor; this has an optional parameter that is the base that python has to use to translate the argument (it may also be a string). The default values is base=10, since it is the way we are use to read numbers (while machines works in binary, so base=2). If the base is greater then 10 that the numbers start to be encoded with letters ( base[0, 10] = [0, 10], base[11, 27] = [A, Z])\n",
    "\n",
    "Python has some built-in function to translate the most common base like `bin()` for binary `hex()` for hexadecimal.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "```py\n",
    "bin(10) = 0b1010 # the 0b is telling us that the base 2 (binary)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rational Numbers\n",
    "Rational numbers are those number which are not integer and can be represented with a finite number of digits or translated into a fraction of rational numbers. The module `fraction` can be used to represent rational numbers, since the float representation can be misleading due to machine precision."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "```py\n",
    "from fraction import Fraction\n",
    "\n",
    "Fraction(1,2) #(numerator, denominator)\n",
    "Fraction('0.125')\n",
    "Fraction(22/7)\n",
    "\n",
    "# CAVEAT\n",
    "'''\n",
    "Some numbers can't have a finite representation due to machine precision. For example 0.3 it is actually an approximation. The problem is that we have to look at something like the 20th decimal position in order to realize that this is the case. If we pass this number to Fraction() we would imagine to receive 3/10 as output; instead we would get a fraction of very huge numbers that best approximate that imprecision in the machine representation of 0.3 (0.2999999999999999999998977..)\n",
    "'''\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Floats (Real Numbers)\n",
    "In CPython floats are implemented as `C double` which implements the `binary64` (IEEE 754).\n",
    "Floats use a fixed size of 64 bits divide as follow:\n",
    "\n",
    "- sign -> 1 bit\n",
    "- exponent (in the range[-1022, 1023]) -> 11bit\n",
    "- significant digits -> 52 bit (15-17 significant digit in base_10)\n",
    "\n",
    "To have a precise representation of real numbers (since float may be effected by machine precision), we can use the `decimal` module."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "# decimal representation of a real number\n",
    "123.45 = 1*10^3 + 2*10^1 + 3*10^0 + 4*10^-1 + 5*10^-2 \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### equality\n",
    "Care must be taken when looking at the equality of floats since there are some decimal numbers that cannot be represented by a finite binary representation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.30000000000000004441\n",
      "0.29999999999999998890\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# base_10(0.1) = base_2(0.0 0011 0011 0011 ...) \n",
    "# therefore\n",
    "x = 0.1 + 0.1 + 0.1 \n",
    "y = 0.3 \n",
    "\n",
    "print(f'{x:.20f}')\n",
    "print(f'{y:.20f}') \n",
    "x == y "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One workaround is to set a range delta (es. a percentage of the size of the larger number involved in the equality operation) as discriminant values to determine if two numbers are equal:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "|a - b| < epsilon\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pythonic way to approach this problem is to use the module `math.isclose` with the care of specifying appropriate relative and absolute tolerance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "# math.isclose(x, y, rel_tol, abs_tol)\n",
    "math.isclose(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Booleans PEP 285\n",
    "Booleans are a subclass of the int class (i.e. it inherits all its methods). Two constant are defined: `True` (int = 1) and `False` (int = 0). They are Singleton objects, i.e. the point to a fixed address in memory and can be compared with the identity and the equality operator aswell. N.b. even if True and False evaluates to the int 1 and 0 respectively, they don't point ot the same memory address, since they are not the same type of object:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(True) == 1 and int(False) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id(True) != id(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id(False) != id(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Objects have an associated `truth value`, meaning that they have a defined truth state. In particular, every object will evaluate to `True` by default except for:\n",
    "\n",
    "- None\n",
    "- False\n",
    "- 0 (in any numeric type, float, complex ..)\n",
    "- empty sequence (list, tuple string..)\n",
    "- empty mapping (dictionary, sets..)\n",
    "- implementing __bool__ or __len__ in a custom class\n",
    "\n",
    "Has a matter of fact, when we call `bool()` on an object, it will look for the definition of the dunder method `__bool__`, if this is not defined, then it will look for the `__len__` method and if also this is not defined the it will evaluate to `True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# es. __bool__ implementation for the int class\n",
    "def __bool__(self):\n",
    "  return self != 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Booleans operators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "# Truth Table\n",
    "X Y  not X  X and Y  X or Y\n",
    "0 0    1       0       0\n",
    "0 1    1       0       1\n",
    "1 0    0       0       1 \n",
    "1 1    0       1       1\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "# De Morgan's Theorem\n",
    "not(A or B) == (not A) and (not B)\n",
    "not(A and B) == (not A) or (not B)\n",
    "\n",
    "# Operations precedence (in descending order)\n",
    "< > <= >= == != in is\n",
    "not\n",
    "and\n",
    "or\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Short-Circuiting\n",
    "Looking at a truth table there are two case in which the program can simply is job evaluating only part of a boolean statement. Thi is called `short-circuiting`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "True or Y # -> True \n",
    "# with an or statement, id the first argument is True it doesn't matter whether the second argument is True or False, the operation will always evaluate to True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "False and Y # -> False\n",
    "# with an and statement, id the first argument is False it doesn't matter whether the second argument is True or False, the operation will always evaluate to False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is very useful when we have to concatenate two conditions together, one of the which may results in rising an exception (and breaking the code) if evaluated. With short-circuiting we can add a first statement that check for a particular exception that may rise with second argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_string = 'ciao'\n",
    "if 'a' == my_string[0]:\n",
    "  pass\n",
    "# we are checking if 'a' is the first letter of my_string. But what happen if my_string is empty? the code breaks. We can solve this with short-circuiting the first\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "string index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_43728/1172889395.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmy_string\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mif\u001b[0m \u001b[0;34m'a'\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mmy_string\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: string index out of range"
     ]
    }
   ],
   "source": [
    "my_string = ''\n",
    "if 'a' == my_string[0]:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if my_string and 'a' == my_string[0]:\n",
    "  pass\n",
    "# Since an \"and\" expression will evaluate to True only if the two members are True, we can safeguard our code from breaking checking first if my_string evaluates to False (i.e. if is an empty string);\n",
    "# if it is so, the second part of the \"and\" statement won't be executed thus safeguarding our code of breaking due to IndexError exception."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "back to [TOC](#TOC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iterable and Iterators\n",
    "---\n",
    "Iterables are, in essence, containers that can be iterated, nothing more. For example, sequences are particular iterables upon which we can iterate on an index-base, but this is not always the case for an iterbale. An iterable only need the concept of `next` item, meaning that it should return another element from the container, without any ordering implied. Moreover iterators needs to keep track of the elements that have been handed out, since we don't want the same element twice, and a stopping creterion is needed to tell us when the container is exhausted and no more elements are available. Other features are: having a finite number of elements in the container, the possibility to \"start from the beginning\" i.e. reuse the iterable if needed, the use of list comprehension etc..\n",
    "\n",
    "Python has a special method called `next()` that lives under `__next__` and fit exaclty the purpose of iteraring over an iterable, i.e handing out a new elemnt each time it is called on an iterable. We also have a built-in exception that is made to check if the iterable is exhausted, this is `StopIteration`.\n",
    "\n",
    "Let's imagine we want to create our custom iterable class, how can we tell Python how to behave properly on the `__next__` method? how to not exhaust our class instance once we have iterated over all the elements? \n",
    "To answer this we need to use a **`protocol`** i.e. a way to tell to the python interpreter that our class has to implement certain functionality.\n",
    "\n",
    "In particular, for an `iterator` we need a `iterator protocol` that requires the class to have 2 methods:\n",
    "* `__iter__` a method that should only return the class instance (why???)\n",
    "* `__next__` to handle the elements return and the eventual raise of StopIteration\n",
    "\n",
    "If our class satify this prerequisite than we have an **`iterator`** upon which we can use for loops, list comprehension etc.. except for the reusability of the iterable, once it is consumed it has to be reinstaciated.\n",
    "\n",
    "At the end, the solution to our problem is to have two distinct objects: the `iterable` that is the collection of the elements, it never get exhausted, it is just a container; and the `iterator`, a copy of the iterable object that is responsible for iterating over the elements. the iterable is created once while the iterator is created any time we want to restart the iterating process. This is a good deal form amny reasons, for example we may have a use set of data stored in our iteable and we don't want to reload them each time we need to restart the iteration!\n",
    "\n",
    "As a formal distinction, an `iterable` is a python object that implement an `iterable protocol` that only requires the definition of the `__iter__` method which will return a new instance of the iterator each time is called:\n",
    "\n",
    "```py\n",
    "class Iterator\n",
    "    def __init__(self):\n",
    "        pass\n",
    "        \n",
    "    def __iter__(self): # return itself\n",
    "        return self\n",
    "        \n",
    "    def __next__(self):\n",
    "        # criterion for StopIteration\n",
    "\n",
    "class Iterable:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "        \n",
    "    def __iter__(self): # return the iterator\n",
    "        return Iterator(self)\n",
    "```\n",
    "\n",
    "Basically, we are not iterating over the instance of the iterable object but over the iterator generated by the iterable itself! \n",
    "\n",
    "N.B. when we ask python to iterate over an object it will first look for the `__iter__` method and only after for the `__getitem__` method. This means that if we implement both in our custom class, during iteration python will use the former.\n",
    "\n",
    "Python has different built-in (lazy) iterable and iterators and it is fundamental to know who is what now that we know the difference between the two constructs:\n",
    "\n",
    "* `range()` -> iterable\n",
    "* `dict.keys()` / `values()` / `items()` -> iterable\n",
    "* `zip()` -> iterator\n",
    "* `enumerate()` -> iterator\n",
    "* `open()` -> iterator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Consume iterators manually\n",
    "Imagine we need to parse a csv file  where the first two lines are the header and the data types. We could essentially do a for loop with nested if condition to split the header and the data type from the actual data or we could apply what just learned about iterators. Essentially we want to create and iterator from the iterable (the file to be parsed) and assign directly the headers and the data types to a variable and performe a for loop only on the data rows.\n",
    "\n",
    "```py\n",
    "with open(data_file.csv) as file:\n",
    "    file_iter = iter(file)\n",
    "    header = next(file_iter) # first row\n",
    "    data_types = next(file_iter) # second row\n",
    "    data = [row for row in file_iter] # from the third row and on\n",
    "```\n",
    "\n",
    "The results is a very clean and efficient way to parse the file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lazy Iterables\n",
    "Let's first define what is a **Lazy Evaluation**: it is often referred to class properties that are not directly evaluated when the instance of the class is created but are computed, and becomes available, only when the propety is requested. Once the propery is requested for the first time, its value is cached in the instance state, therefore it doesn't need to be computed again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import pi\n",
    "\n",
    "class Circle:\n",
    "    def __init__(self, r):\n",
    "        self.radius = r # using the setter\n",
    "        self._area = None # Lazy area\n",
    "        \n",
    "    @property\n",
    "    def radius(self):\n",
    "        return self._radius\n",
    "    \n",
    "    @radius.setter\n",
    "    def radius(self, r):\n",
    "        self._radius = r\n",
    "        self._area = None # reset area when the radius is changed\n",
    "        \n",
    "    @property\n",
    "    def area(self):\n",
    "        if self._area is None:\n",
    "            print('Calculating area')\n",
    "            self._area = pi*self.radius**2\n",
    "            #return self._area\n",
    "    \n",
    "        return self._area # if area was not None we already have the cached value   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c1 = Circle(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if called again\n",
    "c1.area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now the result is cached\n",
    "c1.area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if the radius is changed\n",
    "c1.radius = 3\n",
    "c1.area"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This concept can be applied also to iterables, and in fact it is something used very often in python `generators`; essentially, the element is returned only when `next()` is called. Fro example we can create an infinte lazy iterable that will compute factorial only when requested."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import factorial\n",
    "\n",
    "class Factorial:\n",
    "    def __iter__(self):\n",
    "        return self.FactIter()\n",
    "    \n",
    "    class FactIter:\n",
    "        def __init__(self):\n",
    "            self.i = 0 # initializer\n",
    "            \n",
    "        def __iter__(self):\n",
    "            return self\n",
    "        \n",
    "        def __next__(self):\n",
    "            f = factorial(self.i)\n",
    "            self.i += 1\n",
    "            return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = iter(Factorial())\n",
    "for _ in range(10):\n",
    "    print(next(f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the code we can se that the iterable has almost nothing to do, all the computation is carried out in the iterator class. `enumerate()` and `zip()` are built-in lazy iterator of the python stack."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## iter() method\n",
    "What happens when we call `iter(obj)`? Python essentialy first look for an `__iter__` method defined in the object class, if not, it look for the `__getitem__` method where basically the iterator is created over a sequence that is iterated with `next` as if it were a while loop, catching the exception for `IndexError` and raising the `StopIteration`. Folloqiong an example of a Sequence-Iterator class (something very similar to what python does when we call `iter()` on an object that has only `__getitem__` defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SeqIter:\n",
    "    def __init__(self, seq):\n",
    "        self.seq = seq\n",
    "        self.index = 0\n",
    "        \n",
    "    def __iter__(self):\n",
    "        return self\n",
    "    \n",
    "    def __next__(self):\n",
    "        try:\n",
    "            item = self.seq[self.index]\n",
    "            self.index += 1\n",
    "            return item\n",
    "        except IndexError:\n",
    "            raise StopIteration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iter() with callables\n",
    "There is a second form of the `iter()` method that is useful to iterate over callables. In the form `iter(callable, sentinel)` we can specify a sentinel argument wich is the criterion to call the StopIteration on the iterable. Of course, if the sentinel value is never met, we'll generate an infinite iterable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def call():\n",
    "    i = 0\n",
    "    \n",
    "    def inner():\n",
    "        nonlocal i\n",
    "        i += 1\n",
    "        return i\n",
    "    return inner\n",
    "\n",
    "inner = call()\n",
    "iter_call = iter(inner, 5) # set the sentinel value to 5\n",
    "\n",
    "for c in iter_call:\n",
    "    print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delegating Iterators\n",
    "Let's imagine we have a class that is storying a list of elements in a pseudo-private variable (i.e. beginning with \\_). Once an instance of the class is created, unless specifically implemented, we cannot iterate over this list (unless we are aware of the private variable, but aniway shouldn't be the case). On option could be to add the capability to the class to generate an iterator out of that list, but it is code that we dont want to handle directly. What we can do is to `delegate` the generation of the iterator to the `iter` method itself; in this way we only need to implement the `__iter__` method in our class. As a matter of fact, in real practice we will often not create a custom iterable, unless we need specific functionality, but we'll leverage the `iter()` method, delegating to it theduty of returning an iterator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Delegate:\n",
    "    def __init__(self, some_list):\n",
    "        self._somelist = some_list\n",
    "        # do something to this list\n",
    "        \n",
    "    def __iter__(self):\n",
    "        return iter(self._somelist)\n",
    "    \n",
    "# since some_list is already an iterable (a list) we can create easily an iterator with iter().\n",
    "# In this way the class Delegate is simply trasformed in an iterable!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reversed Iteration\n",
    "It may happen to need to iterate over an iterable in reversed order, and what we usually do is to use a for loop and slicing like:\n",
    "```py\n",
    "for i in lst[::-1]:\n",
    "    print(i)\n",
    "```\n",
    "In this way we are creating a copy of the list, maybe only to iterate over some few elements in a huge sequence! A quite bad looking sintax solution would be to iterate backwards knowing the length of the sequence:\n",
    "```py\n",
    "for i in range(len(lst)):\n",
    "    print(lst[-i-1])\n",
    "```\n",
    "However, the best approach, both in terms of efficiency and readability, is tu tranform the list in a `reversed iterator`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq = [i for i in range(5)]\n",
    "for s in reversed(seq):\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the method `reversed()` is creating an iterator of the iterable seq, therefore we are not creating a copy of the sequence. What Python does behinde the scene is to call the `__reversed__` method, and this is it , at least for sequence type.\n",
    "\n",
    "However, the same does not apply if we want to reverse iterate over a general iterable that doesn't support indexing. In this case we need the `__reversed__` method to return an iterator. As for the `iter()` method, python will first search for the `__reversed__` method, and if don't find it it wil look for both the `__getitem__` and `__len__` methods (basically to do what we have shown before with the for loop)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Caveats: usign iterators as function arguments\n",
    "Due to the fact that we can only iterate once over an iterator before it is exhausted, we need to be careful to use it as a function argument. \n",
    "\n",
    "Let's immagine that we created a class that returns an iterator consisting in a list of numbers: now suppose we need to find the max and the min betweeen these. If we call, for example the `min()` method we will get the minimum values, but to get this python had to iterate over the iterator exhausting it! Therefore, if now we ask for `max()` we'll incurr in a `ValueError` since our iterator has reached the `StopIteration` condition with the `min()` method and now it is nothing more than an empty sequence!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "back to [TOC](#TOC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generators\n",
    "---\n",
    "Generators are functions that contain at least one `yield` statement, are essentially iterator (iterato protocol implemented), and are inherently lazy.\n",
    "\n",
    "Let's imagine we want to create a function that can be stopped during execution (like a for loop that is stopped at each iteration) so that we can handle the data to do something else before the function is exhausted. In python there is a particular keyword called `yield` which emits a value and pause the function execution; than it can be resumed calling `next`. Once the function execution is finished, a `StopIteration` exception is raised."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# es.\n",
    "def using_yield():\n",
    "    print('Name')\n",
    "    yield 'Giovanni'\n",
    "    print('Surname')\n",
    "    yield 'Frison'   \n",
    "    \n",
    "test = using_yield()\n",
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, `test` is not a function but a `generator object` upon which we can call the `next()` method to execute the body until a `yield` statement is reached."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As for an iterator, when the function body is exahusted, i.e. no yield statment remains, the `StopIteration` is raised.\n",
    "\n",
    "A function that use the `yield` statment in his body is called `generator function` and is essentially a `generator factory`. The `using_yield` function above is just a regular function, but since it contains a `yield` in the body, python compiler knows that it is a generator function/factory, and each time it is called a generator is created. In this way we are able to execute the function piece-wise, one `yield` statement at the time, exiting and re-entering the fucntion in different part of our code, calling `next` on the generator function.\n",
    "\n",
    "The generator behave like an iterator because it is an iterator! it has the iterator protocol implemented (`__iter__` and `__next__` methods). As a matter of fact, generatos are powerful tools to create iterator in a very effective way. Es. looking at the Factorial implementation that can be found in [Lazy Iterables](#Lazy-Iterables) section, we can easily re-implementing it using a yield statement:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def factorials(n):\n",
    "    for i in range(n):\n",
    "        yield math.factorial(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in factorials(5):\n",
    "    print(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iterables from generators\n",
    "Being an iterator, a genrator has the same caveat, meaning that once it is exhausted it has no use and sometimes this can lead to unwanted bugs in our code. However, there is a solution to this, we could make an iterable from our generator simply by defining an iterable class that in the `__iter__` method returns not `self` but an instance of our generator. Let's look at an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def square_gen(n):\n",
    "    for i in range(n):\n",
    "        yield i ** 2\n",
    "\n",
    "sq = square_gen(4)\n",
    "for s in sq:\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, we created a generator factory (`square_gen`) and a generator from it (`sq`) that it now exhausted due to the for loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sq' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_43728/3683673336.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'sq' is not defined"
     ]
    }
   ],
   "source": [
    "list(sq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, we can define a custom iterable ourself (implementing the iterable protocol)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Square:\n",
    "    def __init__(self, n:int):\n",
    "        self.n : int = n\n",
    "            \n",
    "    # iterable protocol\n",
    "    def __iter__(self):\n",
    "        # we need to retunr an iterator or in this case \n",
    "        # our generato function\n",
    "        return Square.square_gen(self.n) \n",
    "    \n",
    "    @staticmethod # it doesn't use any of the class properties\n",
    "    def square_gen(n):\n",
    "        for i in range(n):\n",
    "            yield i ** 2   \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can call `sq` as many time as we want since it time is automatically returning a new instance of the generator function `square_gen`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sq = Square(4)\n",
    "for s in sq:\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(sq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generator expressions\n",
    "Using the same sintax of list comprehension we can create generator expression, the only difference is in that generators wants round brackets `()`. The advantage of generator expressions is that they are ineherently `lazy`, meaning that the expressions are not evaluated until requested by the `next()` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0, 1, 4, 9, 16], <generator object <genexpr> at 0x7f62cc076f90>)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lst = [i ** 2 for i in range(5)] # iterable\n",
    "gen = (i **2 for i in range(5)) # iterator\n",
    "\n",
    "lst, gen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "comparing list and generator comprehension we have:\n",
    "* list takes longer to create since they have to evaluate each expression, while generator are returned immediately\n",
    "* list iteration is faster since the object has already been created\n",
    "\n",
    "Therefore, we canc conclude that:\n",
    "* if we need to iterate over all the elements, the  time performance is almost the same, but generators occupy less space since once iterated are destroyed\n",
    "* If we need to iterate only on some elements then generators are the way to go, since we don't compute all the unwanted iterations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Yield from\n",
    "In it easiest application, `Yield from` is just a way to replace a for loop over an iterable inside a generator expression. Let's take for example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loop_on_nested_generator(n):\n",
    "    gen = ((i*j for i in range(1,n+1)) for j in range(1,n+1))\n",
    "    for row in gen:\n",
    "        for item in row:\n",
    "            yield item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "2\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "loop = loop_on_nested_generator(2)\n",
    "for l in loop:\n",
    "    print(l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead we can sustitute the last for loop with a `yield from` an achieve the same result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yield_from_nested_generator(n):\n",
    "    gen = ((i*j for i in range(1,n+1)) for j in range(1,n+1))\n",
    "    for row in gen:\n",
    "        yield from row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "2\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "loop = yield_from_nested_generator(2)\n",
    "for l in loop:\n",
    "    print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "back to [TOC](#TOC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequence Type\n",
    "---\n",
    "In math terms a sequence is nothing more than a countable group of items that have a positional ordering, meaning that each element can be accessed by an index representing its position. In Python, a `list` is a sequence type while a `set` is not since it doesn't have a positional order.\n",
    "A sequence can be `mutable` (list, bytearrays) or `immutable` (string, tuples, range, bytes). \n",
    "Again, sequence can be `homogeneous`, if they held elements of the same type (like strings) or `heterogenuos` (lists). \n",
    "A sequence is also an `iterable type` since we can reach each element one-by-one hence iterating over the sequence (n.b. an iterbale is not always a sequence, set is an example).\n",
    "\n",
    "Common methods on sequence are:\n",
    "* `in` and `not in`\n",
    "* `+` for concatenation (not for range type)\n",
    "* `* int` for repetition (not for range type)\n",
    "* len() to retrieve the length of the sequence\n",
    "* index(x) to retrieve the occurence of element x\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mutating sequence\n",
    "\n",
    "With mutation in Python we refer to the change in the internal state of a mutable object without modifying it memory address. For example list concatenation is not a mutation since a new object is created while usign the method `append` is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# concatenation\n",
    "l = ['Giovanni']\n",
    "l_id = id(l)\n",
    "l = l + ['Frison']\n",
    "id(l) == l_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# appending\n",
    "l = ['Giovanni']\n",
    "l_id = id(l)\n",
    "l.append('Frison')\n",
    "id(l) == l_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other mutation can be achieved with:\n",
    "* slicing assignation -> `s[i] = x`\n",
    "* delete of elements -> `del s[i]`\n",
    "* removing all the objects in the container -> `s.clear()`\n",
    "* inserting elements -> `s.insert(i, val)`\n",
    "* extend with another iterable -> `s.extend(iterable)`\n",
    "* pop (return and remove the element at index i) -> `s.pop(i)`\n",
    "* remove the first occurrence of x -> `s.remove(i)`\n",
    "* reverse in-place -> `s.reverse()`\n",
    "* and many more ..\n",
    "\n",
    "N.B. not all the sequence type must have this methods, in particular if custom made by us"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### in-place concatenation and repetition\n",
    "Sequence can be concatenate or repeted using the `+` or the `*`. If We do it in the stadard way we obtain a new object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l1 = [1,2,3]\n",
    "l2 = [4,5,6]\n",
    "l1_prev_id = id(l1) \n",
    "l1 = l1 + l2\n",
    "\n",
    "id(l1) == l1_prev_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "however, if the sequence is mutable, we use inplace concatenation `+=` or repetition `*=` we are mutating the object, therefore the `id` remain the same. If the sequence is immutable, like a tuple, a new object will be created anyway."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l1 = [1,2,3]\n",
    "l2 = [4,5,6]\n",
    "l1_prev_id = id(l1) \n",
    "l1 += l2\n",
    "\n",
    "id(l1) == l1_prev_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mutation by assignment\n",
    "Some mutable sequence, like lists, support the assignment via index, meaning that we can replace elements by assigning new values to the list. This works also with slices provided that the we provide as substituing value an iterable, and it doesn't even need to be of the same length of the slice we are replacing! We can aslo have stepwise slices as a replacement, but in that case the length of the iterable must match the number of element selected. In the same way we can delete elements just by replacing a slice with an empty list. At last, usign a trick we are also able to insert an iterable inside a sequence: first we need to create an empy assignation to  a slice on the same index e.g. `l[1:1] = []`, and then we can assign an iterable to that slice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a', 'b', 'c', 'd', 3, 4, 5, 6, 7, 8, 9, 10]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# replacing a slice with as many elements as we want\n",
    "l = [1,2,3,4,5,6,7,8,9,10]\n",
    "l[:2] = ['a', 'b', 'c', 'd'] # place 4 elements instead of the first 2\n",
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a', 2, 'b', 4, 'c', 6, 'd', 8, 'e', 10]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# replacing a stepwise slice with the same number of element selected\n",
    "l = [1,2,3,4,5,6,7,8,9,10]\n",
    "l[::2] = ['a', 'b', 'c', 'd', 'e'] # 5 element change with 5 element\n",
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6, 7, 8, 9, 10]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# delete elements\n",
    "l = [1,2,3,4,5,6,7,8,9,10]\n",
    "l[:5] = []\n",
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 2, 3, 2, 3, 4, 5, 6, 7, 8, 9, 10]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# insert elements\n",
    "l = [1,2,3,4,5,6,7,8,9,10]\n",
    "l[1:1] = []\n",
    "l[1:1] = [1,2,3]\n",
    "l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Never return a mutated object\n",
    "If we write a plain function it is best practice not to modify the element we are passing as argument but return a modified copy of it. So called `in-place methods` are generally bouded to classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([3, 2, 1], [3, 2, 1])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what we should do\n",
    "def reverse(s):\n",
    "    s.reverse()\n",
    "\n",
    "# what we shoudn't do\n",
    "def reverse(s):\n",
    "    s.reverse()\n",
    "    return s\n",
    "\n",
    "s1 = [1,2,3]\n",
    "s2 = reverse(s1)\n",
    "\n",
    "s1, s2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Copying Sequences\n",
    "\n",
    "While copying immutable sequence is in general a safe procedure, the same cannot be stated about mutable ones. A trivial example comes from care concatenation and repetition, because the repeting/concatenating will create a copy of the object and if we then modify one of the copy, the same happen to the other."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shallow copies\n",
    "We created a function that apply an in-place method to the argument `s` of the function and then `return s`. The user then expect to use that return and assign the function call to a variable `s2` thinking that he created a new object while instead `s2` is now poiting to the same object of `s1` that as been modified as well. What we should do is **not** returning the function.\n",
    "\n",
    "Even better, it would be not to do in-place modification to our objects, but create a copy first and than pass it to the function that modifies it. To copy a sequence, or any objects, there are a variety of ways, some more pythonic then others:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, False, [True, True, True])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ways of coopying a list creting a new object but leaving the same\n",
    "# memory reference to the elements inside the list\n",
    "\n",
    "s = [1, 2, 3]\n",
    "\n",
    "# 1. simple loop (horrible)\n",
    "cp = []\n",
    "for i in s:\n",
    "    cp.append(i)\n",
    "    \n",
    "# 2. list comprehension\n",
    "cp = [i for i in s]\n",
    "\n",
    "# 3. copy method (not for immutable sequence like tuple or strings)\n",
    "cp = s.copy()\n",
    "\n",
    "# 4. slicing (with tuple the same element is returned)\n",
    "cp = s[:len(s)]\n",
    "\n",
    "# 5. list method (with tuple the same element is returned)\n",
    "cp = list(s)\n",
    "\n",
    "\n",
    "# therefore we have\n",
    "s == cp,  s is cp,  [s[i] is cp[i] for i in range(len(s))]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we have performed are called `shallow copies`, i.e. we have created a copy only of the sequence object but the elements inside have the same memory reference. If these elements are immutable objects than the copy is safe, meaning that we can modifying it without affecting the source. However, if the sequence contains mutable objects then a shallow copy may not be enough. Lets see an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 2], [3, 4]]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = [[1, 2], [3, 4]]\n",
    "l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now `l` is a sequence that contains 2 mutable objects. We can create a copy and try to sustitute one of its element and see what happens:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(False, ['python', [3, 4]], [[1, 2], [3, 4]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cp = l.copy()\n",
    "cp[0] = 'python'\n",
    "cp is l, cp, l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The copy `cp` is actually a new object, and when we say `cp[0] = 'python'` we are actually mutating this object, without affecting the original list `l`. but what happens if we try to modify the mutable objects inside `cp` (which share the same memory reference with the one contained in `l`)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([[100, 2], [3, 4]], [[100, 2], [3, 4]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cp = l.copy()\n",
    "cp[0][0] = 100\n",
    "cp, l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see noth the inner list in `cp` and `l` have been modified, this because the `l.copy()` is a shallow copy and effetcs only the outer object. As a matter of fact:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, True)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cp[0] is l[0], cp[1] is l[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep Copies\n",
    "\n",
    "To performe a copy at the deepest level of an object a recursive approach, able to handle circular references, is needed. Python has the built-in module `copy` to carry out a deep copy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([[100, 2], [3, 4]], [[100, 2], [3, 4]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from copy import deepcopy\n",
    "cp = deepcopy(l)\n",
    "l, cp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(False, False)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cp[0] is l[0], cp[1] is l[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the deepcopy is intelligent enough to retin references also after the deep copy. Lets see an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MyClass:\n",
    "    def __init__(self, a):\n",
    "        self.a = a\n",
    "        \n",
    "x = MyClass(100)\n",
    "y = MyClass(x)\n",
    "lst = [x, y]\n",
    "\n",
    "x is y.a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now `lst` is a sequence that contains two elements, `x` and `y` that has an attribute `y.a` that point to `x` (not a circular reference. Now if we performe a deepcopy, python will create new objects for each element, but will retain the relationship between `y.a` and `x`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(False, False)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cp = deepcopy(lst)\n",
    "# now even if we have different objects\n",
    "x is cp[0], y is cp[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the relationship is retained\n",
    "cp[0] is cp[1].a # same of x is y.a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Slicing\n",
    "\n",
    "Slicing is an opertaion that works with indexing, therefore it is appliecable only to sequence type objects. A `slice` is an object of type slice that can also be created, and assigned to a varible, with the keyword `slice()`.\n",
    "Slicing always return a new object\n",
    "\n",
    "The esiest way to slice is specify the star and stop:\n",
    "* `l[i:j]` with i included and j excluded\n",
    "\n",
    "Slice are independente from the sequence they are slicing, therefore even if the stop of the slice is out of bound for the sequence, python won't throw an error but slice to the end of the sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([1, 2, 3], [3, 4, 5])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = [1,2,3,4,5]\n",
    "l[0:3], l[2:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is possible also to specify a third argument for the slice which is the step (or stride), default to 1. Moreover, if the stop argument is not given, python automatically considere the `len` of the sequence as stopping point; same goes for the start argument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 3, 5]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l[::2] # start:stop:step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a conseguence, it is easy to reverse a list with slicing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5, 4, 3, 2, 1]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l[::-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general, we can have arguments of th slice that are greater the the length of the sequence or even negative. To understand which range are we actually taking into account we need to remeber the folloqing rules:\n",
    "\n",
    "given `l[i:j:k]`:\n",
    "\n",
    "* if `k > 0`:\n",
    "    * if `i, j > len(seq)` -> `len(seq)`\n",
    "    * if `i, j < 0` -> `max(0, len(seq) + i(or j)`\n",
    "    * if `i` is omitted or `None` -> `0`\n",
    "    * if `j` is omitted or `None` -> `len(seq)`\n",
    "* if `k < 0`:\n",
    "    * if `i, j > len(seq)` -> `len(seq) - 1`\n",
    "    * if `i, j < 0` -> `max(-1, len(seq) + i(or j)`\n",
    "    * if `i` is omitted or `None` -> `len(seq) - 1`\n",
    "    * if `j` is omitted or `None` -> `-1`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If in the end we are not sure of the slices we are doing, or we don't remember this rules, we can create a slice object with `i,j,k` needed and the use the method `indices()` that will return the indices `i,j,k` corresponding to the `range(i,j,k)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 5, 2)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slice(0,6,2).indices(len(l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([1, 2, 3, 4, 5], [1, 3, 5])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# which is equivalent to\n",
    "l, list(map(lambda x: l[x], range(0, 5, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Sequences\n",
    "An essential feature that as to be implemented in a custom sequence object is the `__getitem__` method since it is the one that make possible to iterate over the sequence enabling all sort of iterations, from list comprehension to for loops. The `__getitem__` method should be coded in order to handle positive and negative integers as well as slice objects. An idea of implementation could be the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    " class MySequence(object):\n",
    "        \n",
    "    def __init__(self, length):\n",
    "        if isinstance(length, int):\n",
    "            self.length = length\n",
    "            self.sequence = [i for i in range(length)]\n",
    "        else:\n",
    "            raise TypeError('Length must be an integer.')\n",
    "            \n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f'{self.__class__.__name__}(length={self.length})'\n",
    "        \n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        if isinstance(index, int):\n",
    "            if index < 0: # handle negative index\n",
    "                index = self.length + index\n",
    "            if index < 0 or index > self.length: # handle out of bound index\n",
    "                raise IndexError\n",
    "            else:\n",
    "                return self.sequence[index]\n",
    "\n",
    "        elif isinstance(index, slice):\n",
    "            start, stop, step = index.indices(self.length)\n",
    "            rng = range(start, stop, step)\n",
    "            return [self.sequence[i] for i in rng]\n",
    "\n",
    "        else:\n",
    "            raise TypeError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], 0, 9, [1, 2])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq = MySequence(10)\n",
    "list(seq), seq[0], seq[-1], seq[1:3],"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mutation in custom sequences\n",
    "We have seen that mutating a sequence means to change it without creating a new object. Example of mutation can be concatenation or repetition and these can happen also in-place. To add this capability to our custom sequence we need to `overload` the definition of the symbols `+, +=, *, *=` by implementing the methods `__add__` and `__iadd__` or `__mul__` and `__imul__`. \n",
    "\n",
    "Other common methods that we could implement in our sequence are:\n",
    "* `__setitem__` as the complement of `__getitem__`\n",
    "* `__contains__` to add the `in` functionality to check if an element is in the sequence\n",
    "* `__delitem__` to delete elements with the keyword `del`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sorting sequences\n",
    "Python as a built-in sorting method called `sorted()` with a default ascending order and an optional parameter `reverse=False`. When talking about ordering we have to take into consideration that, excecpt for numbers, it is not trivial to have a ordering criterion for each type of object. An easy example is with strings, that can be ordered lexicographically, but what about lower and upper case? In python for example, the convention is that lower cases come first, i.e. `'a' > 'A'` (ASCII charchters have a code that can be retrieved with `ord(str)`).\n",
    "\n",
    "In some case, when the arguments are not directly comparable because they dont have a natural ordering, we need to create a `sorting key`, ie.e a rule that will help python understand which is the order it has to consider:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'<' not supported between instances of 'str' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_43728/2097657746.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'a'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'x'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Z'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'?'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'A'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# the key argument is not provided hence python will try to sort in natural order\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: '<' not supported between instances of 'str' and 'int'"
     ]
    }
   ],
   "source": [
    "l = [1,'a', 'x', 'Z', '?', 100, 'A']\n",
    "sorted(l) # the key argument is not provided hence python will try to sort in natural order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_func = lambda x: ord(str(x)) if isinstance(x, str) else x \n",
    "sorted(l, key=l_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sorting return a copy of the iterable with the sorted elements in a list, use the TimSort algorithm (after Tim Peters, author of `import this` the zen of python). Also, it is a `stable sort`, meaning that if, given a key or not, there is equality in the order of two elements, the one that appear first before the sorting will be the first also after the sorting. Lists object have a `sort()` method that instead is an in-place sorting. They have the same algorithm but the `sorted()` method have a greater overhaed since it has to create a copy of the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zero-based Index\n",
    "\n",
    "Why are python sequence indexed starting with `0` and not `1` ?  \n",
    "\n",
    "Essentially Because:\n",
    "* we want to describe a range of indices using `range(l, u)` with `l <= n < u`\n",
    "* in this way the length (number of elements) is precisely the upper bound of the sequence (`l - u`)\n",
    "* if we want to know how many elements precede the element `s[i]`, in a base-0 system is exaclty `i`\n",
    "* the only starnage behavior is the last index of a sequence which is `len(s) - 1`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Application - `Polygon`\n",
    "Link to [Polygon_Class](Polygon_Class.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lists vs Tuples\n",
    "\n",
    "Lets look at the difference between lists and tuples (as immutable data-structure) and in particular why tuples are more efficient and should be used instead of lists if the mutability is an attribute not required.\n",
    "\n",
    "To do this, we have first to definte what `constant folding` is: the process of recognize and evauating constant expressione at compile time and not at run time as computation.\n",
    "\n",
    "To look at the different compilation of lists and tuples we'll make use of the `dis` module that essentially disassemble the steps that the python compiler execute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dis import dis\n",
    "\n",
    "# let's compile a tuple and a list and disassemble the process\n",
    "list_dis = dis(compile(\"[1,2,3,'a']\", 'string', 'eval'))\n",
    "tuple_dis = dis(compile(\"(1,2,3,'a')\", 'string', 'eval'))\n",
    "\n",
    "list_dis, tuple_dis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the huge difference in compilation between tuples and list; the first load only one constant representing all the elements while the latter load one element at the time. In this case both the containers have immutable elements, but if the tuple contains a mutable object (es. a list) then the compilation advantage is lost, since first python build the list and only after the tuple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dis(compile(\"(1,2,3,['a'])\", 'string', 'eval'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Copying\n",
    "\n",
    "There is a difference in copying a list and a tuple since one is mutable and the other not. If for example we do a shallow copy of a list, a new object is created, with a tuple instead, since it doesn't make sense for python to have two identical immutable objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1 = [1,2,3,4]\n",
    "t1 = (1,2,3,4)\n",
    "l2 = list(l1) # shallow copy\n",
    "t2 = tuple(t1)\n",
    "\n",
    "l1 is l2, t1 is t2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Storing Efficiency\n",
    "\n",
    "From Python 3.8 there is not much difference in storing efficiency between tuple and list if the dimension of the final object is known. therefore there is little difference in storage between doing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "l = list(range(100))\n",
    "t = tuple(range(100))\n",
    "\n",
    "sys.getsizeof(l), sys.getsizeof(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, if the final dimension of the sequence is unkown, i.e. we append elements to the list, then the list constructor allocate extra memory when it sees that the size is being filled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = list()\n",
    "size_prev = sys.getsizeof(l) # to catch the overhead of list creation\n",
    "\n",
    "for i in range(10):\n",
    "    l.append(i)\n",
    "    size_l = sys.getsizeof(l)\n",
    "    delta, size_prev = size_l - size_prev, size_l\n",
    "    print(f' n° item: {i+1}, list size: {size_l}, delta:{delta}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "back to [TOC](#TOC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iteration Tools - The itertools module\n",
    "---\n",
    "The itertools module is a collection of lazy iterator functions (i.e. very efficient) that can be very usefull in different situations. In this section we will look to several functions that can leverage the use of the itertools module."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregators\n",
    "aggregators are function that iterate over an iterable and return a bulk summary of the its content as a singel value. Example are the functions `max()`, `min()`, `sum()` etc.. \n",
    "\n",
    "The function `any()` and `all()` are usefull agregator that looks at the truth values of the elements inside an iterator. `any()` will return `True` if at least one element evaluates to `True` while `all()` will evaluate to `True` only if all the elements evaulate to `True`.\n",
    "\n",
    "N.B. remember that in Python every object has an associated truth value that by default evaluate to `True`. Only elements like `0`, `''`, `None`, `[]` evaluate to `False`. The truth values can be coded also in a custom class by defininig a specific rule in the `__bool__` method. If the bool method is ont defined, python will look for the `__len__` method, where 0 evaulate to `False`. If neither of the two is defined, the custom object will evaulate to `True` by default.\n",
    "\n",
    "A `predicate` is a function that takes a single argument and return `True` or `False`, like `bool()`, and can be used in conjunction with `all()` or `any()`. Let's say for example that we want to find if all the elements in a list are greater then 0. We could for sure iterate over the whole list, but a more clever way is to apply a predicate to the list and then check the content with `all()`. In this way if, for example there is an element < 0 in the first position, the program won't waste resources iterating over the whole list, saving memory and time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = [0, -1, 10, 5, -3, 6]\n",
    "gen = (l >= 0 for l in lst)\n",
    "all(gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## iSlicing\n",
    "Slicing is the operation of cutting a sequence type object in different ways. The classical notation is composed by up to three terms `[i:j:k]` respectively the start, stop and step parameters. However, with classical slicing is not possible to slice iterables. To do this, we have the `itertools.islice` method.\n",
    "\n",
    "Of course, `islice` is a lazy iterators, that iterate over an iterable and return a lazy evaluated slice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import islice\n",
    "result = islice(lst, 0, 3)\n",
    "result, list(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the result of `islice` is an iterator, once we have mapped it into a list, it is exahusted, therefore we won't be able to use it again. As a matter of fact, calling `list` again will result in an empty list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting and Filtering\n",
    "\n",
    "Python has a builting function `filter` that takes an iterable and a predicate and return an iterator. What it doesn under the hood is basically forming a generator expression that loops over the iterable veryfing the predicate on each element."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = [1, 2, 3, 4, 5]\n",
    "list((l for l in lst if l>3)), list(filter(lambda x: x>3, lst))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "as expected the two methods are exactly equivalent, both return an iterator that once iterated is exausted. \n",
    "\n",
    "From the itertools module we have some lazy version of the filter function, for example `filterfalse` that will essentially filter the negation of the predicate function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import filterfalse\n",
    "lst = [0, '', 'ciao', 1]\n",
    "list(filterfalse(None, lst)) \n",
    "# N.B. if None is supplied as predicate python will look at the truth values of each element"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "another usefull itertools function for selecting and filtering is `compress` wich takes two iterables, one with the data to be selected and one with a series of selector (values that explicitly evaluates to True or False), adn maps the two. The result is a lazy iterator that contains only the elements in the first iterable that were in the position that evaluated to True in the second one. Better an example than 1000 words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import compress\n",
    "lst = [1, 2, 3, 4 ,5, 6]\n",
    "test = [True, False, None, 0, 1]\n",
    "list(compress(lst, test))\n",
    "# N.B. if the lst has more elemtns than test, the remaining are evalutated to None and therefore discarted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `takewhile` function takes an iterable and a predicates as arguments and returns an iterator that yield values until the predicate evaluates to `True`; when a `False` evalutation is encountered, at that point the iterator is exahusted. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import takewhile\n",
    "lst = [1,2,3,5,2,1]\n",
    "list(takewhile(lambda x: x<5, lst))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, when `takewhile` encoutered a predicated that evaluated to `False` (5<5) it stopped yielding eveen if the last elemebts would evaluate to `True`.\n",
    "\n",
    "Similarly `dropwhile` will do the opposite, it will start yield values from the iterable as soon as the predicated evaluate to `False` the first time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import dropwhile\n",
    "lst = [1,2,3,5,2,1]\n",
    "list(dropwhile(lambda x: x<5, lst))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Infinite iterators\n",
    "From the itertools module we also have a set of infinite iterators that can comes handy. `count` for example  is a function similar to `range`, since we can define a start and a step, but it has no stop parameter. Moreover, start and step can be an numeric type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import count, takewhile\n",
    "list(takewhile(lambda x: x < 11,count(10, 0.3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `cycle` function let us iterate over an iterable or an iterator (yes, also an iterator) over and over. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import cycle\n",
    "lst = [1, 2, 3, 4]\n",
    "match  = ['a', 'b']\n",
    "for i, j in zip(lst, cycle(match)):\n",
    "    print(i, j)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `repeat` instead simply yields the same element indefinitely, or a defined number of time if specified. N.B. the elemetn that is repeated is actually alwasy the same object!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ciao\n",
      "ciao\n",
      "ciao\n"
     ]
    }
   ],
   "source": [
    "from itertools import repeat\n",
    "ciao = repeat('ciao')\n",
    "for _ in range(3):\n",
    "    print(next(ciao))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chaining and Teeing\n",
    "\n",
    "Chaining is essentially the operation of concatenate multiple iterables together, something that we can easily fo with the `+` sign. What `itertools.chain` add is the ability to concatenate iterators lazily. `chain(*args)` takes a variable number of arguments that can be iterable or iterators. However, there is a caveat: imagine we have list `l` containing 3 iterators that we want to chain, if we pass `l` with unpacking we are losing the lazyness since unpacking with `*` is an eager procedure (it requires python to iterate over the object to unpack, and if it is an iterator it will exhaust it). In order to pass directly an iterable there is a dedicated method in the chain module: `itertools.chain.from_iterable`, another lazy iterators!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 4, 0, 1, 8, 0, 1, 16]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from itertools import chain\n",
    "\n",
    "l1 = (i**2 for i in range(3))\n",
    "l2 = (i**3 for i in range(3))\n",
    "l3 = (i**4 for i in range(3))\n",
    "\n",
    "list(chain(l1,l2,l3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we try to use an iterable of iterators:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<generator object <listcomp>.<genexpr> at 0x7f62cc07dc80>,\n",
       " <generator object <listcomp>.<genexpr> at 0x7f62cc07dc10>,\n",
       " <generator object <listcomp>.<genexpr> at 0x7f62cc07dba0>]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = [(i**j for i in range(3)) for j in range(2,5)]\n",
    "list(chain(l))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we get back is a list of the generators created inside `l` and not their chaining.\n",
    "\n",
    "Instead if we use the `.from_iterable` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 16, 0, 1, 16, 0, 1, 16]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(chain.from_iterable(l))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since iterator are one-time-use it can be beneficial to be able to create copies if we need to use them more than once in our code. The simplest way would be to use a for loop to populate, let's say, an empty list with an arbitrary number of calls of our generator function, however python has a smarter way to do it. The operation is called  \"Teeing\" and is performed by the `itertools.tee` function that will take 2 arguments, an iterable/iterator and the number of time we want to copy it. The copies will be independent object with different memory address.\n",
    "\n",
    "N.B. what come back from `tee` is always an iterator even if the object passed was an iterable!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<itertools._tee at 0x7f62cc083600>,\n",
       " <itertools._tee at 0x7f62cc0e5900>,\n",
       " <itertools._tee at 0x7f62cc0e5600>,\n",
       " <itertools._tee at 0x7f62cc126c80>,\n",
       " <itertools._tee at 0x7f62cc150840>)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from itertools import tee\n",
    "\n",
    "def square(n):\n",
    "    for _ in range(n):\n",
    "        yield n**2\n",
    "        \n",
    "single_iterator = square(5)\n",
    "\n",
    "multiple_iterators = tee(single_iterator, 5)\n",
    "\n",
    "multiple_iterators\n",
    "# each object in the tuple has a different memory address!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mapping and Accumulation\n",
    "Mapping is essentially the application of a callable (a function) to every element of an iterable, something that can be easily achieved with the `map` function (return a lazy iterator), a list comprehension or a generator function.\n",
    "\n",
    "Of course, itertools has its own mapping function to work with iterators. `starmap` is similar to map but it is able to unpack every sub element of the iterable and mapping to a function. Moreover, we can pass to `starmap` a function that takes multiple argument, ideally a number equal to the number of elements in the nested iterables. As for every function in the itertools module, what is returned by starmap is a lazy iterator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6, 12]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from itertools import starmap\n",
    "l = [[1,2,3], [3,4,5]]\n",
    "list(starmap(lambda x, y, z: x + y + z, l))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accumulation is a process that reduce an iterable to a single value; es. the `sum` function or more generally the `reduce` function (lazy iterator), which has the advantage to take an arbitrary function to apply to each element of the iterable and also to specify an initializer (see [Partial functions](#Partial-functions))\n",
    "\n",
    "Itertools has a function similar to `reduce` that is called `accumulate` which take an iterable and a function as arguments (it doesn't support an initializer) and returns (lazily) each intermediate result of the accumulation process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24, [1, 2, 6, 24])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from itertools import accumulate\n",
    "from functools import reduce\n",
    "import operator\n",
    "\n",
    "lst = [i for i in range(1,5)]\n",
    "\n",
    "reduce(operator.mul, lst), list(accumulate(lst, operator.mul))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zipping\n",
    "The classic built-in `zip` function is a lazy iterator that takes an arbitrary number of iterables and return an iterator that produces tuples. If the iterables passed have different length, the shortes will command the lenght of the resulting iterator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 'a', 10), (2, 'b', 20)]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the shortest iterable command the iterator length\n",
    "list(zip([1,2], ['a', 'b', 'c'], [10, 20, 30 , 40]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, we may want to zip on the longest iterable, filling the holes with a predetermined value. To do this we have the `itertools.zip_longest` which takes a variable number of iterators as well, but it let us specify a `fillvalue` (defaulted to `None`) that will serve as a placeholder for the shorter iterables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 'a', 10), (2, 'b', 20), ('Filled', 'c', 30), ('Filled', 'Filled', 40)]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from itertools import zip_longest\n",
    "list(zip_longest([1,2], ['a', 'b', 'c'], [10, 20, 30 , 40], fillvalue='Filled'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grouping\n",
    "Sometimes, while iterating over an iterable, let's say a list of tuples, we may need to group the elements based on a specific pattern or a key. To do this there is the function `itertools.groupby` wich takes an iterable, a key function and returns a lazy iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "key is 1\n",
      "resulting in group:\n",
      "[(1, 10, 100), (1, 11, 101), (1, 12, 102)]\n",
      "\n",
      "key is 2\n",
      "resulting in group:\n",
      "[(2, 20, 200), (2, 21, 201)]\n",
      "\n",
      "key is 3\n",
      "resulting in group:\n",
      "[(3, 30, 300), (3, 31, 301), (3, 32, 302)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from itertools import groupby\n",
    "\n",
    "iterable = [(1, 10, 100), (1, 11, 101), (1, 12, 102),\n",
    "            (2, 20, 200), (2, 21, 201),\n",
    "            (3, 30, 300), (3, 31, 301), (3, 32, 302)]\n",
    "\n",
    "groups = groupby(iterable, lambda x: x[0]) # key function groubing based on the first element of the tuples\n",
    "for group in groups:\n",
    "    print(f'key is {group[0]}')\n",
    "    print(f'resulting in group:\\n{list(group[1])}', end='\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "calling next on the sub iterator `group[1]` will actually consumes the original iterator created upond the iterable passed as argument to `groupby`. However, if we decide to skip iterating, let's say, on the second group of elements, when we call next on the third group, python automatically iterates also over the second in order to return in output the elements of the correct group.\n",
    "\n",
    "N.B. `groupby` will create groups with elements that consecutively have the same key, it doesn't sort the iterbale first, therefore, depending on the need, it migh be needed to pre-sort the iterables before passing it to `groupby`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Caveat: lazy iterators in I/O operation\n",
    "Imagine we want to read a csv file that contains a list of products (brand, product) in rows; we want to group this data by the the brand and we opt to use the `itertools.groupby function`. We can immagine to structure something like this:\n",
    "\n",
    "```python\n",
    "from itertools import groupby\n",
    "\n",
    "with open('my_file.csv') as f:\n",
    "    grouped = groupby(f, lambda x: x[0])\n",
    "```\n",
    "\n",
    "Now we surely would expect to be able to look at the grouped iterator by, for example, castin it to a list:\n",
    "\n",
    "```python\n",
    "list(grouped)\n",
    "```\n",
    "\n",
    "however, what we would have in return is a `ValueError: I/O operation on closed file.`. this is because `groupby` is a lazy iterator and therefore it won't actually evaluate its content untill requested, that in our case is outside the `with` statement, i.e. when the file `my_file.csv` has already been closed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combinatorics\n",
    "The itertools module has also some useful functions realted to combinatorics; as a matter of fact we have `permutations`, `combinations` and `cartesian product` of multiple iterables, all returning a lazy iterators."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cartesian Product\n",
    "The cartesian product is the conbination of all the elements in 2 or more sets (don't need to be of the same length). In 2 dimension is something that we do preatty often, and can be achieved easily with a nested for loop, but when the dimension start to increase it can become messy. To easily handle an `n-dimensional` cartesian product we can use the `itertools.product` which takes an arbitrary number of arguments and return lazily their cartesina product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 1), (1, 2), (1, 3), (2, 1), (2, 2), (2, 3), (3, 1), (3, 2), (3, 3)]"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from itertools import product\n",
    "\n",
    "l1 = [1,2,3]\n",
    "l2 = [1,2,3]\n",
    "\n",
    "list(product(l1, l2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Permutations\n",
    "Statistically speaking, simple permutations are all the possible combinations (without repetition, i.e. no duplicates element are present in the set) of all the elements in a set. Givena set of dimension `n` the toal number of permutation is given by `n!`. To performe a permutation in python we can rely on the `itertools.permutations` function wich takes as argument an iterable and, optionally, the length of the permutation. There is a caveat thou, since all the elements in an iterable, say a list, are distinct objects even if they have the same value; this means that, in case of duplicated values in an iterable, the permutation will contains an apparent repetition, which in reality is not because the object underlying is being switched in potition generating *de facto* a new permutation. **Elements are unique based on their position, not their value!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('a', 'b'), ('b', 'a')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from itertools import permutations\n",
    "\n",
    "string = 'abc'\n",
    "\n",
    "list(permutations(string))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "but, be careful, uniqueness is given by position not values, therefore if we a duplicate value in a different position, this result in a new object, therefore, not counting as a duplicate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('a', 'b', 'a'),\n",
       " ('a', 'a', 'b'),\n",
       " ('b', 'a', 'a'),\n",
       " ('b', 'a', 'a'),\n",
       " ('a', 'a', 'b'),\n",
       " ('a', 'b', 'a')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string = 'aba'\n",
    "\n",
    "list(permutations(string))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combinations\n",
    "Unlike permutations, combinations don't care about the order of the elements (i.e `'ab'=='ba'`). Combinations can be defined `without replacement`, meaning that once an element is picked from a set it cannot be picked again, and `with replacement`. To perform combinations in python we can use the `itertools.combinations` or i`tertools.combinations_with_replacement`; both functions take an iterable and an the optional length of the combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 2), (1, 3), (2, 3)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from itertools import combinations\n",
    "\n",
    "l1 = [1,2,3]\n",
    "\n",
    "list(combinations(l1, r=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 1), (1, 2), (1, 3), (2, 2), (2, 3), (3, 3)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from itertools import combinations_with_replacement\n",
    "\n",
    "l1 = [1,2,3]\n",
    "\n",
    "list(combinations_with_replacement(l1, r=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "back to [TOC](#TOC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Strings\n",
    "---\n",
    "\n",
    "Strings are immutable object of the sequence type, therefore they have indices and can be used as an iterator. String are an homogeneous containers with fixed length and order."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Common methods\n",
    "- isalpha() -> check if is alphanumeric\n",
    "- isprintable() -> check if is printable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "back to [TOC](#TOC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lists\n",
    "---\n",
    "List are mutable object 0f the sequence type... (to be extended)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List comprehension\n",
    "The goal of list comprehension is to **generate a list by `tranforming`, and optionally `filtering`, another iterable**.\n",
    "\n",
    "Like a function, list comprehension have a localscope (what is inside the sqaured brackets is essentially the body of a function) but they can freely access also the globalscope. As a matter of facts, when python compile the list comprehension rhs, it creates a temporary function which is essentially the equivalent of a for loop (with eventual if statements). This also implies that, after the excution, the varibale inside the local scope are deleted and can't be retrieve in the global namespace.\n",
    "\n",
    "We can try to disassemble a list comprehension to see whats happening:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1           0 LOAD_CONST               0 (<code object <listcomp> at 0x7f62cc07ed40, file \"string\", line 1>)\n",
      "              2 LOAD_CONST               1 ('<listcomp>')\n",
      "              4 MAKE_FUNCTION            0\n",
      "              6 LOAD_CONST               2 ((1, 2, 3))\n",
      "              8 GET_ITER\n",
      "             10 CALL_FUNCTION            1\n",
      "             12 RETURN_VALUE\n",
      "\n",
      "Disassembly of <code object <listcomp> at 0x7f62cc07ed40, file \"string\", line 1>:\n",
      "  1           0 BUILD_LIST               0\n",
      "              2 LOAD_FAST                0 (.0)\n",
      "        >>    4 FOR_ITER                12 (to 18)\n",
      "              6 STORE_FAST               1 (i)\n",
      "              8 LOAD_FAST                1 (i)\n",
      "             10 LOAD_CONST               0 (2)\n",
      "             12 BINARY_POWER\n",
      "             14 LIST_APPEND              2\n",
      "             16 JUMP_ABSOLUTE            4\n",
      "        >>   18 RETURN_VALUE\n"
     ]
    }
   ],
   "source": [
    "from dis import dis\n",
    "\n",
    "compiled = compile('[i**2 for i in (1,2,3)]', filename='string', mode='eval')\n",
    "dis(compiled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "as we can see, python is create a function `4 MAKE_FUNCTION` "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List comprehension can be nested one inside the other, creating closures betwen themself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 0, 0, 0, 0], [0, 1, 2, 3, 4], [0, 2, 4, 6, 8]]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lst = [[i*j for i in range(5)] for j in range(3)]\n",
    "lst "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List comprehension can have as many nested for loop as we want:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0, 0), (0, 0, 1), (0, 1, 0), (0, 1, 1), (1, 0, 0), (1, 0, 1), (1, 1, 0), (1, 1, 1)]\n",
      "[(0, 0, 0), (0, 0, 1), (0, 1, 0), (0, 1, 1), (1, 0, 0), (1, 0, 1), (1, 1, 0), (1, 1, 1)]\n"
     ]
    }
   ],
   "source": [
    "l = []\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        for k in range(2):\n",
    "            l.append((i,j,k))\n",
    "            \n",
    "            \n",
    "l_1 = [(i, j, k) for i in range(2) for j in range(2) for k in range(2)]\n",
    "\n",
    "print(l)\n",
    "print(l_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the order in the for loop is the same in the list comprehension\n",
    "\n",
    "We can also add if statement inside the for loop and of course the order matter! They have to be referenced after the for loops."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0), (1, 1)]\n",
      "[(0, 0), (1, 1)]\n"
     ]
    }
   ],
   "source": [
    "l = []\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        if i == j:\n",
    "            l.append((i,j))\n",
    "            \n",
    "l_1 = [(i, j) for i in range(2) for j in range(2)  if i == j]\n",
    "\n",
    "print(l)\n",
    "print(l_1)     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can add an else statement, but in this case the `if..else` statement must come before the for loop. since it acts like a filter for the for expression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0), 'else', 'else', (1, 1)]\n",
      "[(0, 0), 'else', 'else', (1, 1)]\n"
     ]
    }
   ],
   "source": [
    "l = []\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        if i == j:\n",
    "            l.append((i,j))\n",
    "        else:\n",
    "            l.append('else')\n",
    "            \n",
    "l_1 = [(i, j) if i == j else 'else' for i in range(2) for j in range(2)  ]\n",
    "\n",
    "print(l)\n",
    "print(l_1)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1162910910.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipykernel_43728/1162910910.py\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    l_1 = [(i, j)  for i in range(2) for j in range(2) if i == j else 'else' ]\u001b[0m\n\u001b[0m                                                                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "l_1 = [(i, j)  for i in range(2) for j in range(2) if i == j else 'else' ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "back to [TOC](#TOC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuples\n",
    "---\n",
    "Tuple are known as immutable list, they are object of the sequence type, therefore they have indices and can be used as an iterator. Tuples can be homogeneous or heterogeneous containers. Together with immutability, in comparison with lists, the main difference are that tuples have a fixed length and a fixed order (cannot be im-placed sorted or reversed like lists).\n",
    "\n",
    "Due to this property, we can think of tuples as data records, where the position of the data, one define have a precise meaning:\n",
    "\n",
    "```py\n",
    "# Circle(x, y, radius)\n",
    "circ1 = (0, 0, 10)\n",
    "```\n",
    "Once we have define the structure of our container, tuples can be used to store data efficiently, since once created we are sure that nobody will be able to accidentally modify it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Named Tuples\n",
    "Sometimes, defining a custom class can be an excessive effort if what we want to achieve is simply storing data in a custom data structure. Classes require at least some methods to be implemented to be property employed in our code (such the `__eq__` and `__repr__` method for example); moreover the instance of a class is not immutable and can lead to potential errors. On the opposite, plain tuples are immutable and well opt to store data, but accessing properties with indices can be troublesome for the user or even for other developer to read. \n",
    "\n",
    "```py\n",
    "# Class vs tuple approach\n",
    "class Person:\n",
    "\n",
    "    def __init__(self, name, age)\n",
    "    self.name = name\n",
    "    self.age = age\n",
    "\n",
    "p1 = Person('Luca', 44)\n",
    "p1.name, p1.age # 'Luca', 44\n",
    "\n",
    "p1 = ('Luca', 44)\n",
    "name = p1[0]\n",
    "age = p1[1]\n",
    "```\n",
    "\n",
    "Of course, python as a perfect solution to this kind of problem, i.e. named tuples. `namedtuples` are functions that comes shipped in the `collenctions` standard library; they are a subclass of the `tuple` type but they are not a type them self. Instead, namedtuple is a function that generate a new class (`class factory`) which can assign property names to positional elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "\n",
    "Pt2D = namedtuple('Point2D', ['x', 'y'])\n",
    "\n",
    "# Pt2D is a variable alias of the class `Point2D` generated by the class factory namedtuple\n",
    "\n",
    "pt = Pt2D(x=10,y=20)\n",
    "pt, pt.x, pt.y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each time we call the `Pt2D` functions, python is using the `__new__` method of the `Point2D` class to create a new instance of that object and return the tuple.\n",
    "\n",
    "There are several ways in which we can pass the arguments to the namedtuple function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pt2D = namedtuple('Point2D', ['x', 'y']) # list\n",
    "Pt2D = namedtuple('Point2D', ('x', 'y')) # tuple\n",
    "Pt2D = namedtuple('Point2D', 'x, y') # comma separated strings\n",
    "Pt2D = namedtuple('Point2D', 'x y') # whitespace separated strings\n",
    "\n",
    "# and remember, namedtuple are subclasse of the tuple type\n",
    "pt = Pt2D(x=10,y=20)\n",
    "isinstance(pt , tuple)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Differently from a class instance, since `pt` is a tuple, it is immutable, i.e. we cannot modify its attribute (in a class object we could)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt.x = 100 # cannot do! it is a tuple -> immutable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N.B namedtuple arguments name CANNOT contains underscore!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pt2D = namedtuple('Point2D', 'x _y') # ERROR!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "unless we provide the keyword `rename=True`, in which case the namedtuple will convert the erroneous name into the positional number of the argument preceded by an underscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'namedtuple' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_43728/1538439503.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mPt2D\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnamedtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Point2D'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'x _y'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mpt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPt2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mpt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'namedtuple' is not defined"
     ]
    }
   ],
   "source": [
    "Pt2D = namedtuple('Point2D', 'x _y', rename=True)\n",
    "pt = Pt2D(10, 20)\n",
    "pt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introspection\n",
    "The namedtuple generated classes that are shipped with some methods that can help ud in the introspection of our code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pt2D._fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt._asdict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modify and Extending\n",
    "Namedtuple are immutable in essence but they come shipped with some methods that helps us handling arguments substitutions and extending. Basically the original tuple is overwritten and associated to a new memory address. Looking to Pt2D as example, we can modify its parameters with the method `_replace()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_43728/1614346549.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# pt right now is Point2D(x=10, _1=20)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_replace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mpt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pt' is not defined"
     ]
    }
   ],
   "source": [
    "# pt right now is Point2D(x=10, _1=20)\n",
    "pt = pt._replace(x=50)\n",
    "pt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead, if we want to extend the namedtuple, adding more argument we can use the the `_fields` property of the existing namedtuple (which is a tuple), adding the element/s we want and create the new namedtuple with extended fields:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pt2D = namedtuple('Point2D', 'x, y')\n",
    "old_fields = Pt2D._fields # is a tuple\n",
    "new_fields = old_fields + ('z', ) # concatenation of two tuple\n",
    "Pt3D = namedtuple('Point3D', new_fields) # equal to say Pt3D = namedtuple('Point3D', (x,y,z)) \n",
    "pt = Pt3D(10, 20, 30)\n",
    "pt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Docstring\n",
    "The namedtuple is shipped with a set of precompiled docstrings that can be access as always with the `help()` or the `__doc__` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Pt3D' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_43728/1150487544.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhelp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPt3D\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'Pt3D' is not defined"
     ]
    }
   ],
   "source": [
    "help(Pt3D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defaults values\n",
    "When we create a namedtuple, we cannot specify default arguments. One way to circumvent this would be to define an instance of the namedtuple (e.g. setting all parameters to 0) and then use the `._replace()` method to specify only those arguments that we want to have a default value. Alternatively we can use the `__defaults__` method (it can be use in the same way on any function). To use this last approach on the namedtuple we first need to create a new instance of the class using the `__new__` method and then call the `__defaults__`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# `__defaults__` on a generic function\n",
    "def func(x, y, z):\n",
    "    print(x, y, z)\n",
    "\n",
    "func.__defaults__ = (10, 20) # N.B. The replacement starts from the last parameter\n",
    "func(x=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Pt3D' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_43728/3155873952.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Create a new instance of the Pt3D function setting a default values fro the argument z\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mPt3D\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__new__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__defaults__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mpt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPt3D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mpt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Pt3D' is not defined"
     ]
    }
   ],
   "source": [
    "# Create a new instance of the Pt3D function setting a default values fro the argument z\n",
    "Pt3D.__new__.__defaults__ = (0,)\n",
    "pt = Pt3D(x=10, y=10)\n",
    "pt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "back to [TOC](#TOC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dictionaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From Python 3.6, dictionaries are ordered hasmaps, containing (key,values) pairs. To be noted that while the order of insertion is retained now, if you print a dictionaries, it will be sorted in lexicografical order, therefore dont count on that!\n",
    "\n",
    "Before 3.6, to have an ordered dictionary we would have used the `collections.Orderdict`. this is not completely surpassed since it has some usefull functionalities like `move_to_end` and `popitem(last=False)` to move/pop a key in front or at the end of the dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "back to [TOC](#TOC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unpacking iterables\n",
    "Iterables are `packed` structures that bundle values together (list, tuple, strings, set, dictionary..). As per the world meaning, `unpacking` is an operation that assigned the packed values to variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 2, 3)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a, b, c = [1,2,3]\n",
    "\n",
    "a,b,c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('c', 'i', 'a', 'o')"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a, b, c, d = 'ciao'\n",
    "\n",
    "a, b, c, d\n",
    "# N.B. we can unpack in the same way a dictionary or a set but in that case the order of assignment will be casual because these are unordered types of objects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "It comes handy when we want to swap values between variables:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 10)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = 10\n",
    "b = 20\n",
    "\n",
    "a, b = b, a\n",
    "\n",
    "a, b\n",
    "# this works in python because the RHS is evaluated first, where the memory address of \"b\" and \"a\" is copied in a tuple and only after assigned to the new swap) variables \"a\" and \"b\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unpacking with *\n",
    "We may want to unpack an iterable in more than one variable, and in this case it comes handy the `*` operator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, [2, 3], 4)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = [1,2,3,4]\n",
    "# we want to unpack the first element of l and the others apart\n",
    "#we could do it simply with list slicing and unpacking the\n",
    "a, b = l[0], l[1:]\n",
    "\n",
    "# or in a more elegant way with the * operator\n",
    "a, *b = l # a=1, b =[2,3,4] \n",
    "\n",
    "a, *b, c = l # a=1, b=[2,3], c=4\n",
    "\n",
    "a, b, c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "two starred expressions in assignment (2746844977.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipykernel_43728/2746844977.py\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    a, *b, *c = l # ERROR we can unpack with only one *, otherwise python won't understand who assign to whom\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m two starred expressions in assignment\n"
     ]
    }
   ],
   "source": [
    "a, *b, *c = l # ERROR we can unpack with only one *, otherwise python won't understand who assign to whom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another advantage of the `*` operator is that can be used also with objects that don't support slicing (like sets or dictionaries, since they have no ordering). N.B. if more than one element is unpacked with *, it will always end up in a list (even if, for example, the item unpacked is a tuple).\n",
    "\n",
    "The `*` operator can be used also for unpacking objects on the RHS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1 = [1,2]\n",
    "l2 = [3,4]\n",
    "l = [*l1, *l2] # l=[1,2,3,4]\n",
    "\n",
    "l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With dictionaries we have both keys and values that can be unpacked (unordered unpacking since there is no order!). With the `*` operator we unpack the keys of the dict only, while with the `**` we can unpack both keys and values (N.B. `**` can be used only on the RHS)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = {'a': 1, 'b': 2}\n",
    "d2 = {'b': 3, 'c': 4}\n",
    "d = {*d1, *d2} # d={'a','b','c'} -> n.b. b was not repeated because keys are unique in sets and dictionaries.\n",
    "\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {**d1, **d2} # d={'a': 1, 'b': 3, 'c': 4} -> n.b. b has the values contained in d2 since it was unpacked for second and overwrite the keys from d1.\n",
    "\n",
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nested unpacking\n",
    "We can unpack also nested structures, such as list of lists, with the same operators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, *b, (c, *d) = [1, 2, 3, 'python']\n",
    "\n",
    "a, b, c, d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "back to [TOC](#TOC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loops\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## While loop\n",
    "to generate an infinite loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Infinite Loop\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    print('Infinite Loop')\n",
    "    break # to stop infinite loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`else` statement is executed after a while loop only if it terminates without a `break`\n",
    "\n",
    "`continue` is used to interrupt the execution of the current iteration are restart the loop with the next iteration. Only `finally` statement is executed after a continue statement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try statement\n",
    "test a code block.\n",
    "\n",
    "`except` is used to captures errors and handle exceptions\n",
    "\n",
    "`finally` is a code block that is always executed, whether an exception or a break are invoked"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Common exceptions\n",
    "\n",
    "- ZeroDivisionError\n",
    "\n",
    "-"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "back to [TOC](#TOC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "A first semantic difference in functions is the definition of `parameters` and `arguments`; the first is referred to the variables in the function definition while the second is refereed to the variables passed to the instance of the function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.my_func(a, b)>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def my_func(a, b): # a and b are the parameters of the function\n",
    "  pass\n",
    "\n",
    "x = 10\n",
    "y = 'a'\n",
    "\n",
    "my_func(x, y) # x and y are the arguments of the function\n",
    "\n",
    "my_func"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To be noted that x and y are passed by `reference` to `my_func`, i.e. the memory addresses of x and y are stored into a and b.\n",
    "Therefore, the `Function Scope` contains the memory addresses of the variables that are passed to the function (x and y in the example).\n",
    "\n",
    "Another pythonic difference is the definition of `functions` and `methods`. They are defined in the same way but a method is bound to a class, it is an attribute of the class that is callable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<function inspect.ismethod(object)>, <function inspect.isfunction(object)>)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from inspect import ismethod, isfunction\n",
    "\n",
    "ismethod, isfunction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Docstrings and annotations (PEP 257)\n",
    "N.B. Docstring has to the first line of code in the function/class definition, otherwise it won't be inserted into the `__doc__` method and won't be displayed with the `help()` function.\n",
    "\n",
    "Docstrings (single quote or triple quote) are the way to generate documentation inside the python code. They are different from comments (#) since the former are actually compiled by the interpreter and stored in the `__doc__` property of functions and classes. The `__doc__` property can be invoked with the `help()` function on any object that implements it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function my_func in module __main__:\n",
      "\n",
      "my_func()\n",
      "    Here it goes the doctring that contains\n",
      "    the instruction on function usage and arguments types and boundaries.\n",
      "    This will be displayed invocking the `__doc__` method\n",
      "    with the `help()` function.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def my_func():\n",
    "  '''\n",
    "  Here it goes the doctring that contains\n",
    "  the instruction on function usage and arguments types and boundaries.\n",
    "  This will be displayed invocking the `__doc__` method\n",
    "  with the `help()` function.\n",
    "  '''\n",
    "  pass\n",
    "\n",
    "help(my_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way to document our code is to use annotations. These are not stored in the `__doc__` method but can be invoked by the `help()` function. Annotations can be also functions that are evaluated as constant during first compilation; however they don't bind the code to a specific behavior (a: int -> doesn't bind a to be an int), they are only metadata stored in teh `__annotations__` method which is a dictionary with parameters as key and annotations as values. These can be used by external modules like `Sphinx` to automatically generate documentation for our code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 'string', 'b': 'integer', 'return': 'a string'}"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def my_func(a: 'string', b: 'integer') -> 'a string':\n",
    "  return a*b\n",
    "  \n",
    "my_func.__annotations__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `lambda` expression\n",
    "`lambda` expressions are another way to create function without the `def` statement. They are also referred as to `anonymous functions`. It has to be a single expression, therefore no assignment is allowed aswell as no type hinting (annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(function, 9)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lambda [parameters list]: expression\n",
    "lambda x: x**2\n",
    "lambda x, y: x + y\n",
    "lambda : 'hello' # we can assign 0 parameters and just return a constant\n",
    "\n",
    "# we can assign lambda function to variable and later call it\n",
    "my_func = lambda x: x**2\n",
    "\n",
    "type(my_func), my_func(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The lambda expression generates a `function object` that returns the expression when called."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function Intorspection\n",
    "Function are first-class objects that, when created are shipped with a series of default dunder methods in additions to the ones that we implemented. To look at all the function attributes we can use the built-in function `dir()`. Among the dunders method we have:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name : func\n",
      "default args : ('hello',)\n",
      "deafult kwargs : None\n",
      "code object : <code object func at 0x7f62cc0fb5b0, file \"/tmp/ipykernel_43728/3242595406.py\", line 3>\n",
      "variables names : ('a', 'b', 'c')\n",
      "num of arguments : 3\n"
     ]
    }
   ],
   "source": [
    "# this will be shown with the module\n",
    "# inspect.getcomments()\n",
    "def func(a, b, c='hello'):\n",
    "  pass\n",
    "\n",
    "introspection = {\n",
    "'name' : func.__name__, # the name of the function\n",
    "'default args' : func.__defaults__, # tuple containing default positional parameters\n",
    "'deafult kwargs' : func.__kwdefaults__, # dictionary containing default keyword parameters\n",
    "'code object' : func.__code__, # return a code object which has its own methods:\n",
    "'variables names' : func.__code__.co_varnames, # return the paramters and then the local variables (defined inside the function scope) of the function\n",
    "'num of arguments' : func.__code__.co_argcount, # return the number of parameters except *args and **kwargs\n",
    "}\n",
    "\n",
    "for key, arg in introspection.items():\n",
    "  print(f'{key} : {arg}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also the module `inspect` can be used to retrieve information about the function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# this will be shown with the module\\n# inspect.getcomments()\\n'"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import inspect\n",
    "\n",
    "inspect.getcomments(func) # returns the comment just above the function definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \\*args and **kwargs\n",
    "Unpacking can be done also in functions parameters in order to specify a variable number of arguments as input:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 2, (3, 4))"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def my_func(a, b, *args): # N.B. the name 'args' is just a conventions\n",
    "  return a, b, args\n",
    "\n",
    "a, b, c = my_func(1,2,3,4) # a=1, b=2, c=(3,4)\n",
    "# note that inside function scope, arguments are unpacked into tuples e not lists\n",
    "\n",
    "a, b, c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The positional argument constructor `*args` has to be the last positional argument in the function since it exhaust all the non-assigned positional arguments; after that only keyword arguments are allowed and these can be unpacked with the `**kwargs` parameter. The `*` and `**` operators can be used to limit the use of positional or keyword arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_func(*, name):\n",
    "  # in this way my_func doesn't allow positional arguments.\n",
    "  # name is automatically a keyword argument.\n",
    "  pass\n",
    "\n",
    "def my_func(a, *, name):\n",
    "  # in this way my_func allow only one positional argument `a` and one keyword argument `name'.\n",
    "  # since 'name' is placed after * it means it is a keyword argument\n",
    "  pass\n",
    "\n",
    "\n",
    "def my_func(*, name, **kwarg): # OK\n",
    "  pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "named arguments must follow bare * (1713583272.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipykernel_43728/1713583272.py\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    def my_func(*, **kwarg): # ERROR an explicit keyword argument is required after the `*`\u001b[0m\n\u001b[0m                   ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m named arguments must follow bare *\n"
     ]
    }
   ],
   "source": [
    "def my_func(*, **kwarg): # ERROR an explicit keyword argument is required after the `*`\n",
    "  pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters default\n",
    "Care must be taken when assigning default values to functions arguments, in particular if these are mutable objects. Wehn Python compile the script it stores in memory the function definition and any argument with default values. This means that each time that function is called, if the default parameters is left unchanged, it will use the specified values. In some case it may results in unwanted behaviors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a function that store a message in a log file with the datetime\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "def log(msg, *, dt=datetime.utcnow()):\n",
    "  print(f'{dt}: {msg}')\n",
    "\n",
    "# Now, since the value of dt is stored at runtime, each time we call\n",
    "log('first log')\n",
    "time.sleep(3)\n",
    "log('first log')\n",
    "# we will see that the time printed is alway the same since it has been stored at compilation time as a CONSTANT!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION\n",
    "def log(msg, *, dt=None):\n",
    "  dt = dt or datetime.utcnow() # if dt is false (None) the 'or' statement is executed\n",
    "  print(f'{dt}: {msg}')\n",
    "# we can set dt=None and check if the user actually input a values for dt. If not the function will call datetime.utcnow().\n",
    "# Since this call is performed in the function scope, it gets executed each time the function is called. \n",
    "\n",
    "log('first log')\n",
    "time.sleep(3)\n",
    "log('first log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another example is when we create a mutable object directly as argument of a function. Also in this case, that object is evaluated as a constant at compilation time and reused as reference each time the function is called. This"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function that store values into a list\n",
    "def add_item(item, func_list=[]):\n",
    "  func_list.append(item)\n",
    "  return func_list\n",
    "\n",
    "my_list1 = add_item('banana') # a list is created that references to `func_list`\n",
    "# so if i create another list of items\n",
    "my_list2 = add_item('coca')\n",
    "# now we have:\n",
    "# my_list1 = ['banana', 'coca']\n",
    "# my_list2 = ['banana', 'coca']\n",
    "# because they are both referencing to func_list!\n",
    "\n",
    "my_list1, my_list2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION\n",
    "def add_item(item, func_list=None):\n",
    "  func_list = func_list or list() # short-circuit\n",
    "  func_list.append(item)\n",
    "  return func_list\n",
    "\n",
    "my_list1 = add_item('banana')\n",
    "my_list2 = add_item('coca')\n",
    "\n",
    "my_list1, my_list2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`KEY TAKE-AWAY`: Never use mutable objects as `default` arguments. Instead use None and create the object in the function scope. The only time it can come in handy is when using `memoization` to cache values from a function that is executed multiple times."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Map, Filter and Zip functions\n",
    "N.B. Map anf Filter have been mostly replaced by list comprehension and generator functions.\n",
    "\n",
    "These are `higher order functions` (i.e. function that takes a function as parameter and/or returns a function), `map` return an `iterator` that applies the function to each element in the iterable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map(func, *iterables)\n",
    "\n",
    "def sq(x):\n",
    "  return x**2\n",
    "\n",
    "l = [1, 2, 3]\n",
    "\n",
    "list(map(sq, l)), list(map(lambda x: x**2, l))\n",
    "# map returns a generator, therefore we need to pass it to list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of iterables that are provided to map() is determined by the function that it is passed; if more than one iterable is provided, only the length of the shortest will be mapped. `filter` is a function that takes a function and a single iterable and returns the elements of the iterable that satisfies the condition given in the function, i.e. it filters the iterable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = [0,1,2,3,4,5]\n",
    "\n",
    "list(filter(lambda n: n % 2 == 0, l)) # [0, 2, 4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reducing Functions\n",
    "Also called, accumulators, aggregators or folding functions; are functions that recombine an iterable recursively, returning a single value (es. finding the max in an array, or summing up its elements)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write a reducing function to compute max, min and sum of an iterable.\n",
    "l = [5, 8, 6, 10, 9]\n",
    "\n",
    "add = lambda a, b: a+b\n",
    "find_max = lambda a, b: a if a > b else b\n",
    "find_min = lambda a, b: a if a < b else b\n",
    "\n",
    "def _reduce(fn, sequence):\n",
    "  result = sequence[0]\n",
    "  for x in sequence[1:]:\n",
    "    result = fn(result, x)\n",
    "  return result\n",
    "\n",
    "_reduce(find_max, l), _reduce(find_min, l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `_reduce` takes two arguments, a function (add, find_max or find_min), and sequence of numbers. It applies the function recursively a return a single value (the sum, the max or the min) depending on the function passed.\n",
    "Python has a builtin modules that contain the function `reduce` similar to the one defined above, but that works on any iterables, also non index ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "\n",
    "l = [5, 8, 6, 10, 9]\n",
    "\n",
    "reduce(find_max, l), reduce(lambda a, b: a if a > b else b, l) # find max of l\n",
    "\n",
    "#Reduce has a third argument called 'initializer' that serve as first value for the reduced function. This is to avoid runtime error in the case, for example of trying to apply sum-reduce to an empty list.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other builtin reducing function in python are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max': 4, 'min': 1, 'sum': 10, 'any': True, 'all': True}"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "red_func = {\n",
    "'max': max(l),\n",
    "'min': min(l),\n",
    "'sum': sum(l),\n",
    "'any': any(l), # return True if at least one element in the sequence evaluates to True\n",
    "'all': all(l), # return True if all the elements in the sequence evaluates to True\n",
    "} \n",
    "\n",
    "red_func"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partial functions\n",
    "Partial functions are a way to reduce the number of argument required by a function, setting some of them as default. We could write ourself a wrapper to a function ore use the builtin `functools.partial` module.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a function that compute the power of a number\n",
    "\n",
    "def pow(base, exponent):\n",
    "  return base ** exponent\n",
    "\n",
    "# we can create a partial function that specify the exponent so that it computes alway the square\n",
    "def square(base):\n",
    "  return pow(base, exponent=2)\n",
    "\n",
    "# or we can use the functools.partial module\n",
    "from functools import partial\n",
    "\n",
    "square = partial(pow, exponent=2)\n",
    "\n",
    "'''\n",
    "N.B. if we define a variable prior to the partial definition, and we assign that variable as argument, the argument won't point to the variable but to the values associated with its memory address. therefore even if we change the variable after, the value at which the partial function is pointing will remain the same\n",
    "'''\n",
    "\n",
    "a = 2\n",
    "square = partial(pow, exponent=a)\n",
    "# exponent is pointing at the same memory address of 'a' (the value 2) and not to a itself\n",
    "a = 5\n",
    "\n",
    "square(5) # the value assigned in the square function remain the same (2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The `operator` module\n",
    "The `operator` module is a builtin suits shipped with standard python installation. Its main purpose is to construct functional equivalents to arithmetic operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from functools import reduce\n",
    "from operator import mul\n",
    "\n",
    "# we have seen how we can use lambda expression together with reduce to create recursive functions on sequences\n",
    "reduce(lambda x, y: x*y, [1,2,3,4]) # return the product of the elements of the list\n",
    "# the same can be achieved with the operator.mul\n",
    "multiplication = reduce(mul, [1,2,3,4])\n",
    "\n",
    "multiplication"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a variety of different methods in the operator module, for arithmetic/boolean operations (`mul()`, `add()`, `le()`, `is_()` ..), for sequences handling (`getitem()`, `setitem()`, `delitem()` ...) and for handling functions (`itemgetter()`, `attrgetter()`, `methodgetter()`...). These last ones don't return values but instances of the method called; they become an operator thyself (a function essentially) to be call on another objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 10)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "l = [5, 8, 6, 10, 9]\n",
    "f = itemgetter(1, 3) # create a function that return the item at index 1 and 3\n",
    "\n",
    "f(l) # -> (8, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "back to [TOC](#TOC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classes\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "`__init__` is the default method that is called after the class object is created. The first argument is always `self`, i.e. the instance of the object created calling the class object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(__main__.Rectangle, True)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Rectangle:\n",
    "  def __init__(self, width, height):\n",
    "    self.width = width\n",
    "    self.height = height\n",
    "\n",
    "r1 = Rectangle(10,20)\n",
    "# r1 is a instance of the class Rectangle, referred as `self` inside the class constructor    \n",
    "\n",
    "r1.__class__, isinstance(r1, Rectangle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getters and Setters\n",
    "Getter and setter methods are implemented to impose some dynamics in the class structure. In python there are no private attributes (even if we can specify to the reader that a variable is private beginning its name with _). Setter and getter methods impose to the user some constrains"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overload methods\n",
    "There are some special methods that are built into the `class` constructor and are passed automatically to any instance of the class even if they are not defined explicitly. For example if we call the python method `str` on an instance of the class we will receive a standard output specifying the memory address of the instance. Unless we overwrite or `overload` this method explicitly inside the class definition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \\_\\_str\\_\\_ method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Rectangle: width:10, height:20'"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Rectangle:\n",
    "  def __init__(self, width, height):\n",
    "    self.width = width\n",
    "    self.height = height\n",
    "\n",
    "  def __str__(self):\n",
    "    return f'Rectangle: width:{self.width}, height:{self.height}'\n",
    "\n",
    "r1 = Rectangle(10,20)\n",
    "\n",
    "str(r1) # will print what inside the __str__ method\n",
    "# if __str__ is not defined than the output will be:\n",
    "# <__main__.Rectangle object at \"some memory address\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \\_\\_repr\\_\\_ method\n",
    "It is similar to `__str__` method but its use is more developer-oriented. The repr method should return the string representation of the class instance called"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Rectangle(10, 20)'"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Rectangle:\n",
    "  def __init__(self, width, height):\n",
    "    self.width = width\n",
    "    self.height = height\n",
    "\n",
    "  def __repr__(self):\n",
    "    return f'Rectangle({self.width}, {self.height})'\n",
    "\n",
    "r1 = Rectangle(10,20)\n",
    "\n",
    "repr(r1) # will print what inside the __repr__ method that is exactly Rectangle(10,20), how the object r1 has been created in the first place"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \\_\\_eq\\_\\_ method\n",
    "Is the method needed to compare two objects generated by the same class with the `==` operator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "back to [TOC](#TOC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scopes and Namespaces\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Scope` is the portion of the code in which a variable name is defined; it has an associated `namespace`, essentially a table that lists all the variables in the Scope and the associated memory addresses. There are different `Scope` in python and are defined in a nested structure. At the top, we have the `built-in` scope, the only truly global scopes that exists across each modules of Python, which contains the definitions of core elements such as `True`, `None`, `dict` etc. Nested inside the built-in scope there is the so called `Global` scope (even if it is not global in the sense that exist only inside a single file). Moreover, each function has its own scope, named `Local`, that is created each time the function is called (until the function is not called, the variables defined in its own scope are not compiled, therefore does not exist in the Global scope, where the function is defined)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# module1.py\n",
    "print(True)\n",
    "# both print and True are not defined in the module1 scope, therefore python automatically goes up one level and look up for their definition in the builtin-scope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'new_var_never_used' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_43728/1892695046.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_var_never_used\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# Error! 'a' has not been defined in the module scope and neither is in the built-in scope, therefore Python trows an error `NameError`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'new_var_never_used' is not defined"
     ]
    }
   ],
   "source": [
    "print(new_var_never_used)\n",
    "# Error! 'a' has not been defined in the module scope and neither is in the built-in scope, therefore Python trows an error `NameError`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can summarize that at `compile time` python looks at the code and predetermine which variables will eventually be in the local or global scope. When it encounter a `def` (function), it will look inside of it; if there are assignations (e.g. a = 100), it will understand that that variable will be part of the global scope only, unless the `global a` keyword is specified; if a variable is called but not assigned inside the function (e.g. print(a)), the compiler will determine that it is a non-local reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 0 # global scope/namespace\n",
    "\n",
    "def func1():\n",
    "  print(a) # the compiler understand it is a non-local variable since there is no assignment inside the local scope\n",
    "\n",
    "func1()\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func2():\n",
    "  a = 100 # the compiler knows that this will be a local variable\n",
    "  print(a)\n",
    "\n",
    "func2()\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "def func3():\n",
    "  global a # the compiler knows that this will refer to a global variable\n",
    "  a = 100 \n",
    "  print(a)\n",
    "\n",
    "func3()\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Masking\n",
    "It is defined masking, and should be avoided, when we overwrite a keyword from the built-in scope. Since Python first look at the module scope, if we have assigned a variable to an existing element in the built-in namespace, we will modify its standard behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello world'"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# module1.py\n",
    "print = lambda x: f'Hello {x}'\n",
    "# we are redefining locally the 'meaning' of the variable print so now:\n",
    "print('world') # -> 'Hello world'\n",
    "# python is invoking the local definition of print e not the built-in one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same behavior is applied between Global and Local scopes. When assigning a variable inside a functional scope, python sees it at compilation time and stores it (it will be created only when the function is called but the compiler is already aware that it exists).\n",
    "Therefore, if the same variable exist in the Global scope, when the function is called, it will be masked by the assignation in the local scope."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello 0'"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# del print # remove the previously overwrite of standard print function\n",
    "\n",
    "a = 0 # global scope/namespace\n",
    "\n",
    "def my_func():\n",
    "  a = 100 # local scope/namespace\n",
    "  print(a)\n",
    "\n",
    "my_func() # a = 100, the global scope 'a' has been masked \n",
    "\n",
    "print(a) # a = 0, the global scope hasn't been modified, and the local scope of `my_func` has been destroyed after its execution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is also the possibility to avoid masking by explicitly tell python that the variable assigned in the local spaces are actually owned in the global space. This is done by declaring the `global` keyword at the beginning of a local scope. This is telling the compiler to look first in the global scope for that particular variable and, if not found, to create a new one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello 100'"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = 0\n",
    "\n",
    "def my_func():\n",
    "  global a\n",
    "  a = 100 # local scope/namespace\n",
    "  print(a)\n",
    "\n",
    "my_func() # a = 100, since `global a` has been declared, the variable `a` in the global scope has been modified\n",
    "\n",
    "print(a) # a = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nonlocal scope\n",
    "When we define a function inside another function, a new scope is created which is not the global (module level) scope, nor the local (function level) scope. It is a middle scope called `non-local scope`. Variables belonging to the nonlocal scope are called `free variables`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def outer_func():\n",
    "  x = 10 # local scope of outer_func == non-local scope of inner_func\n",
    "  \n",
    "  def inner_func():\n",
    "    x = 20 # local scope of inner_func\n",
    "  \n",
    "  inner_func()\n",
    "\n",
    "  print(x)\n",
    "\n",
    "# if we call outer_func:\n",
    "outer_func() # x = 10 since the local scope of inner func has not modified the non-local scope (local scope of outer_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the same way as we tell python that a variable in a local scope is `global`, we can specify a variable to be `non-local` (i.e. with the same reference of the one in the outer_func scope). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def outer_func():\n",
    "  x = 10 # local scope of outer_func == non-local scope of inner_func\n",
    "  \n",
    "  def inner_func():\n",
    "    nonlocal x # now the reference of x is shared with the non-local (outer_func) scope\n",
    "    x = 20 # local scope of inner_func\n",
    "  \n",
    "  inner_func()\n",
    "\n",
    "  print(x)\n",
    "\n",
    "# if we call outer_func:\n",
    "outer_func() # x = 20 since the local scope of inner func has modified the non-local scope (local scope of outer_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N.B. if in a local scope we define a `global` variable, python will look in global scope for a match, otherwise it will create the global variable. Instead, when defining a `nonlocal` variable, python will look only in the non-local scope (the local scope of the parent function)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def outer():\n",
    "  x = 0 # local scope of outer\n",
    "  \n",
    "  def inner1():\n",
    "    # local scope of inner1 == nonlocal scope of inner2\n",
    "    def inner2():\n",
    "      nonlocal x\n",
    "      x = 10 \n",
    "    inner2()\n",
    "\n",
    "  inner1()\n",
    "  print(x) # x = 0 because inner2 looked only in its nonlocal scope\n",
    "\n",
    "outer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "back to [TOC](#TOC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Closure\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A `Closure` is a special python constructor that is composed by a function and an extended scope (nonlocal scope) that contains free variables (nonlocal variables). This means that both the functions and the extended scope point to the same object, but python don't do this directly. Instead a `cell object` is created, pointing to the value of the free variable, while the free variable, in both the extended scope and the function scope, point to the cell object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def outer():\n",
    "  a = 10\n",
    "\n",
    "  x = 'python'  #----------\n",
    "                # THIS IS A\n",
    "  def inner():  # CLOSURE\n",
    "    print(x)    #----------\n",
    "  \n",
    "  return inner\n",
    "\n",
    "fn = outer() \n",
    "'''\n",
    "now outer has returned the function inner which should print x without directly containing a reference to the variable.\n",
    "Therefore, since the scope of the function outer is exhausted after it is called, we should expect that the variable x=python is lost and can't be referenced by fn.\n",
    "Instead, it is possible since python, during compilation, sees a Closure and create an intermediate cell object that share the reference to x both from inner and outer functions.\n",
    "'''\n",
    "\n",
    "# x = 'python' #--|\n",
    "                 #|--> cell object --> str object `python`\n",
    "# print(x)     #--|              \n",
    "\n",
    "fn()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both `x` in outer and inner functions point to a `cell object` which contains a reference to another object in memory containing the string `python`. This lets us be able to call the function inner, returned from the function outer, even if the scope of outer is already exhausted. We can inspect the closure and free variables of an object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('x',), (<cell at 0x7f62cc0fa9d0: str object at 0x7f62d1f2e030>,))"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fn = outer()\n",
    "\n",
    "# fn.__code__.co_freevars # (x) while a is not a \n",
    "# fn.__closure__ # cell object at address xxx containing a str object ('python') at address yyy\n",
    "# the memory address of both the `x` (local and free) is the same and pointing to yyy\n",
    "\n",
    "fn.__code__.co_freevars, fn.__closure__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can have multiple instance of the same closure, this means che each time a cell object is created, leaving the behavior of the different instance of the closure independent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 1)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def counter():\n",
    "  # beginning of Closure\n",
    "  count = 0\n",
    "\n",
    "  def inc():\n",
    "    nonlocal count\n",
    "    count += 1\n",
    "    return count\n",
    "  # end of Closure\n",
    "\n",
    "  return inc\n",
    "\n",
    "f1 = counter()\n",
    "f2 = counter()\n",
    "# f1 and f2 behavior is independent\n",
    "\n",
    "f1()\n",
    "f1()\n",
    "f1(), f2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shared extend scope\n",
    "At the same time we can have `shared extended scope` of two different closures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def outer():\n",
    "  count = 0\n",
    "\n",
    "  def inc1():\n",
    "    nonlocal count\n",
    "    count += 1\n",
    "    return count\n",
    "\n",
    "  def inc2():\n",
    "    nonlocal count\n",
    "    count += 1\n",
    "    return count\n",
    "\n",
    "  return inc1, inc2\n",
    "\n",
    "f1, f2 = outer() \n",
    "\n",
    "f1()\n",
    "f2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`f1` and `f2` are two closure that share the free variable `count` therefore both the functions, when called, will increment the value of count. If this behavior is wanted, then no problem, but often happens to share the same free variable without knowing it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<function __main__.<lambda>(x)>,\n",
       " <function __main__.<lambda>(x)>,\n",
       " <function __main__.<lambda>(x)>]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a list of functions that add a two values\n",
    "adders = []\n",
    "for n in range(1, 4):\n",
    "  adders.append(lambda x: x + n)\n",
    "\n",
    "# what we expect to have is a list of functions\n",
    "adders\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# therefore calling \n",
    "adders[1](10) # should return 12 = 10 + 2 \n",
    "# instead all the three functions will add 3, i.e. the last value at which n was pointing to"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`n` is a global variable, and it doesn't get evaluated until the function is called, and at that time, after the for loop is executed is equal to 3. As a matter of fact we don't have a closure since `n` is a global variable. The correct way to achieve this would be:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_adders():\n",
    "  adders = []\n",
    "  for n in range(1, 4):\n",
    "    adders.append(lambda x, y=n: x + y) # in this way we are saving the value of n at each iteration \n",
    "  return adders\n",
    "\n",
    "adders = create_adders()\n",
    "\n",
    "adders[1](10)\n",
    "\n",
    "# since we have specified a default value for `y`, this will be evaluated at creation time, not at runtime (i.e. when the function is called).\n",
    "# `y` won't point to the object `n` itself but to its value at each iteration.\n",
    "# Therefore, `y=n` belong to the local scope of the `create_adders` function, therefore, the functions appended to adders are actually closures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nested Closure\n",
    "It is common, e.g. in decorators, to have nested closures:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "104"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define a function that takes an increment and a starting values and return a function that add the increment each time is called. The\n",
    "def increment(n):\n",
    "\n",
    "  def inner(start):\n",
    "    current = start\n",
    "    \n",
    "    def inc():\n",
    "      nonlocal current\n",
    "      current += n\n",
    "      return current\n",
    "\n",
    "    return inc\n",
    "  return inner\n",
    "\n",
    "# Now inc has two free variables (current, n) one that lives in the `inner` scope and one in the `increment` scope.\n",
    "# if we call:\n",
    "fn = increment(2) # we will return the inner function with the variable n = 2\n",
    "fn.__code__.co_freevars # `n` is the free variable of the closure containing the `inner` function\n",
    "# if we than call:\n",
    "inc_2 = fn(100) # we will return the `inc` function with the variable n = 2 and current = 100\n",
    "inc_2.__code__.co_freevars # `n` and `current` are the free variables of the closure containing the `inc` function\n",
    "# now if we call:\n",
    "inc_2() # -> 102\n",
    "inc_2() # -> 104"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Application\n",
    "\n",
    "*hold*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "back to [TOC](#TOC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decorators\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A decorator is a function that takes a function as argument and returns a closure (that in general accept any number of arguments *args and **kwargs) that contain that same function passed with the addition of extra functionality. Let's see an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def counter(fn): # counter takes a function as argument\n",
    "  count = 0\n",
    "  def inner(*args, **kwargs): \n",
    "    nonlocal count\n",
    "    count +=1\n",
    "    print(f'Function {fn.__name__} was called {count} times')\n",
    "    return fn(*args, **kwargs)\n",
    "  return inner\n",
    "\n",
    "def add(a, b):\n",
    "  return a + b\n",
    "\n",
    "add = counter(add) # closure function is returned by counter()\n",
    "# now add is no more referencing to the 'def add' function but to it's decorated version, returned by counter()  \n",
    "\n",
    "result = add(1, 2) # -> 3\n",
    "result = add(1, 3) # -> 4\n",
    "result = add(5, 2) # -> 7\n",
    "\n",
    "result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the example above, `counter()` is essentially a `decorator`; it takes an arbitrary function with any arbitrary arguments, and return the same function with the new \"ability\" of taking track of how many times it has been called. We reassigned the name add to the decorated function, to pointing out that the function is still the same but now points to the closure returned by `counter()`. Returning a closure is something pretty common in python, therefore and handy way has been defined to decorate a function using the `@` symbol."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# once the function counter has been defined from previous example\n",
    "\n",
    "@counter\n",
    "def add(a, b):\n",
    "  '''Documentation'''\n",
    "  return a + b\n",
    "\n",
    "add(1,2)\n",
    "add(3,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All good so far, but now if we look for the metadata of the function `add` we'll see that these now refers to the closure function `inner` and not to the original definition (`__name__`, `__doc__` etc. point to the closure function). The pythonic solution to this problem is to use the module `functools.wraps`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('inner', None)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add.__name__, add.__doc__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('add', 'Documentation')"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from functools import wraps\n",
    "\n",
    "def counter(fn):\n",
    "  count = 0\n",
    "  @wraps(fn) # we are decorating the inner function\n",
    "  def inner(*args, **kwargs): \n",
    "    nonlocal count\n",
    "    count +=1\n",
    "    print(f'Function {fn.__name} was called {count} times')\n",
    "    return fn(*args, **kwargs)\n",
    "  return inner\n",
    "\n",
    "@counter\n",
    "def add(a, b):\n",
    "  '''Documentation'''\n",
    "  return a + b\n",
    "\n",
    "add.__name__, add.__doc__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple decorators\n",
    "Multiple decorators can be passed to a function; care must be taken to ensure that the order of execution of the two or more decorators respect what wanted by the coder. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dec_1(fn):\n",
    "  def inner(*args, **kwargs):\n",
    "    print('dec_1 called')\n",
    "    result = fn() # calling the decorated function\n",
    "    return result\n",
    "  return inner # return the closure\n",
    "\n",
    "def dec_2(fn):\n",
    "  def inner(*args, **kwargs):\n",
    "    print('dec_2 called')\n",
    "    result = fn() # calling the decorated function\n",
    "    return result\n",
    "  return inner # return the closure\n",
    "\n",
    "\n",
    "@dec_1\n",
    "@dec_2\n",
    "def my_func():\n",
    "  print('my_func called')\n",
    "\n",
    "'''\n",
    "Calling my_func, decorated in this order, is equal to do:\n",
    "\n",
    "my_func = dec_1(dec_2(my_func))\n",
    "\n",
    "Therefore, first the closure dec_2(my_func) is evaluated and passed to dec_1(). \n",
    "Since inside the decorators the print() is executed before the function call (result = fn()), the printing output will be:\n",
    "\n",
    "dec_1 called\n",
    "dec_2 called\n",
    "my_func called\n",
    "\n",
    "because first the dec_1 function is called, it prints its output, then call fn passed as argument, which is dec_2(my_func);\n",
    "therefore dec_2 is called, it prints its output, then call the fn passed as argument, i.e. my_func, that prints its output.\n",
    "N.B. if the print() had been placed after the fn() call, the print-out order would had been reversed!\n",
    "This is to say that depending on the functionality we want to implement with our decorators, the order of application matters!\n",
    "'''\n",
    "\n",
    "my_func()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Memoization\n",
    "Another very powerful application of decorators is called `memoization`, i.e. the process of storing data into cache to avoid excessive recursive calculation (like in the fibonacci or factorial function). Let's take as an example a function to compute the fibonacci value at the n position:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# with recursion\n",
    "def fib(n):\n",
    "  print(f'computing fib({n})')\n",
    "  return 1 if n < 3 else fib(n-1) + fib(n-2)\n",
    "\n",
    "fib(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this way, the function works and it is elegant, but it is not performant since it has to compute each time all the previous numbers in the fibonacci series. A way to solve this problem is to cache the results each time they are computed, and this can be easily implemented creating a class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Fib:\n",
    "  def __init__(self):\n",
    "    self.cache = {1: 1, 2: 1}\n",
    "\n",
    "  def fib(self, n):\n",
    "    if n not in self.cache:\n",
    "      print(f'computing fib({n})')\n",
    "      self.cache[n] = self.fib(n-1) + self.fib(n-2)\n",
    "    return self.cache[n]\n",
    "\n",
    "f = Fib()\n",
    "f.fib(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this way, after creating an instance of Fib(), fibonacci sequence will be stored while computed (n.b. cache won't be shared between instances, each new instance will have its cache empty at the beginning). The same can be accomplished with a closure (i.e. with a decorator):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def fib():\n",
    "  cache = {1: 1, 2: 1}\n",
    "\n",
    "  def calc_fib(n):\n",
    "    if n not in cache:\n",
    "      # cache is a nonlocal parameter\n",
    "      print(f'computing fib({n})')\n",
    "      cache[n] = calc_fib(n-1) + calc_fib(n-2)\n",
    "    return cache[n] \n",
    "\n",
    "  return calc_fib # return the closure\n",
    "\n",
    "f = fib()\n",
    "f(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the function `fib()` to a decorator the path is short; we just need to generalize its structure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def memoize_fib(fib):\n",
    "  cache = dict()\n",
    "\n",
    "  def inner(n):\n",
    "    if n not in cache:\n",
    "      # the decorator is not carrying out the recursion\n",
    "      # it is only caching values\n",
    "      cache[n] = fib(n)\n",
    "    return cache[n] \n",
    "\n",
    "  return inner # return the closure\n",
    "\n",
    "@memoize_fib\n",
    "def fib(n):\n",
    "  print(f'computing fib({n})')\n",
    "  return 1 if n < 3 else fib(n-1) + fib(n-2)\n",
    "\n",
    "fib(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is worth to note that `memoize_fib` is not a general purpose decorator since it does not accept any number of arguments or keyword arguments (*args, **kwargs) as it usually does, but it is precisely built to work with the function `fib`. Another important aspect to handle is to limit the cache size to safeguard the tradeoff between performance and memory usage. Of course python as already a builtin decorator specifically design for memoization. It comes shipped with the `functools` module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from functools import lru_cache # least recently used cache\n",
    "\n",
    "@lru_cache() # lru_cache decorators accept arguments.. see below\n",
    "def fib(n):\n",
    "  print(f'computing fib({n})')\n",
    "  return 1 if n < 3 else fib(n-1) + fib(n-2)\n",
    "\n",
    "fib(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parametrized decorators\n",
    "Parametrized decorators are the ones that can handle arguments (such as `wrap` and `lru_cache`). Imagine we have a decorator that run a function a number of time `n` set by the user:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello my_func was called 3 times'"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def run_n_times(fn):\n",
    "  n =3\n",
    "\n",
    "  def inner(*args, **kwargs):\n",
    "    for _ in range(n):\n",
    "      fn(*args, **kwargs)\n",
    "    return print(f'{fn.__name__} was called {n} times')\n",
    "\n",
    "  return inner\n",
    "\n",
    "@run_n_times\n",
    "def my_func():\n",
    "  print('called')\n",
    "  pass\n",
    "\n",
    "my_func()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, the number of times the function is called has been hardcoded in the decorator, but we want to be able to change that parameter. We can think at something like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "run_n_times() missing 1 required positional argument: 'n'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_43728/1276510445.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# now we would expect to call the decorator as:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;34m@\u001b[0m\u001b[0mrun_n_times\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmy_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'called'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: run_n_times() missing 1 required positional argument: 'n'"
     ]
    }
   ],
   "source": [
    "def run_n_times(fn, n: int):\n",
    "  def inner(*args, **kwargs):\n",
    "    for _ in range(n):\n",
    "      fn(*args, **kwargs)\n",
    "    return print(f'{fn.__name__} was called {n} times')\n",
    "\n",
    "  return inner\n",
    "\n",
    "# now we would expect to call the decorator as:\n",
    "@run_n_times(10)\n",
    "def my_func():\n",
    "  print('called')\n",
    "  pass\n",
    "\n",
    "# but we get an error since run_n_times requires two arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_func():\n",
    "    print('called')\n",
    "    pass    \n",
    "\n",
    "# however, the argument `10` in the decorator call is in the position of `fn`, therefore it won't work.\n",
    "# we could instead apply the decorator indirectly as:\n",
    "my_func = run_n_times(my_func, 3)\n",
    "# and this will work but how to implement the same behavior with the @ method?\n",
    "\n",
    "my_func()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to be able to use the `@` symbol with a decorator that accept arguments, we need that decorator to return a decorator itself when called. The result of `run_n_times(10)` has to be another decorator that actually perform the decoration we want. The solution is straightforward: we need to enclose our decorator in a `decorator factory` that will olds the extra parameters needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_n_times(n: int): # decorator factory\n",
    "\n",
    "  def inner1(fn): # decorator\n",
    "\n",
    "    def inner2(*args, **kwargs):\n",
    "      for _ in range(n):\n",
    "        fn(*args, **kwargs)\n",
    "      return print(f'{fn.__name__} was called {n} times')\n",
    "\n",
    "    return inner2\n",
    "  \n",
    "  return inner1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the call `@run_n_times(10)` actually returns the decorator `inner1` which implement the functionality we originally looked for:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@run_n_times(3) # returns the decorator `inner1`\n",
    "def my_func():\n",
    "  print('called')\n",
    "  pass\n",
    "\n",
    "my_func()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is equivalent to say:\n",
    "my_func = run_n_times(3)(my_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decorator class\n",
    "Not only functions can be used to create decorators factory, but also classes. As a matter of fact, thanks to the `__call__` method, we can replicate the same exact behavior seen in the previous example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyClass:\n",
    "  def __init__(self, n): # the instance of the class become the decorator factory\n",
    "    self.n = n\n",
    "\n",
    "  def __call__(self, fn): # this is the actual decorator\n",
    "    def inner(*args, **kwargs):\n",
    "      for _ in range(self.n):\n",
    "        fn(*args, **kwargs)\n",
    "      return print(f'{fn.__name__} was called {self.n} times')\n",
    "    \n",
    "    return inner # closure\n",
    "\n",
    "@MyClass(3)\n",
    "def my_func():\n",
    "  print('called')\n",
    "\n",
    "my_func()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monkey Patching and Decorating classes\n",
    "Functions are not the only object that can be decorated; Classes too can thanks to the dynamic behavior of python that allows the so called `Monkey Patching`, i.e. the modification/addition of attributes/methods to classes at runtime. Essentially, we are able to mutate the behavior of a class at runtime. Imagine we are using the class `Fraction` and we want to add to it some functionality; we can do the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fractions import Fraction\n",
    "\n",
    "f = Fraction(2,3) # create an instance of the Fraction class\n",
    "# we want the class `Fraction` to be able to speak ...\n",
    "# if we write:\n",
    "Fraction.speak = 100\n",
    "# we are Monkey Patching the class Fraction at runtime, so if following we say:\n",
    "\n",
    "f.speak"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can make the `Monkey Patched` methods also callable, for example using a lambda function (we can directly patch the class instead of an instance of it):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fraction.speak = lambda self, message: f'Fraction says {message}'\n",
    "\n",
    "# we need `self` as argument because we will pass to the method an instance of the class Fraction\n",
    "# Now we can call:\n",
    "f.speak('You cannot pass!') # -> 'Fraction says You cannot pass!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see how the process of monkey-patching is essentially a decoration of a class and, as a matter of fact it can be done with a decorator function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decorator_speak(cls): # we are passing a class to the function\n",
    "  cls.speak = lambda self, message: f'{self.__class__.__name__} says {message}'\n",
    "  return cls # return is only needed if we want to decorate with the `@` symbol\n",
    "\n",
    "# Now we can simply write on any class:\n",
    "class Person:\n",
    "  pass\n",
    "\n",
    "Person = decorator_speak(Person) # indirect decoration\n",
    "p = Person() # instance of the class\n",
    "p.speak('I am ALIVE!') # method inherited from the decorator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do something more useful; Imagine we want to debug an existing class creating a decorator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def info(obj): # think of this as of the method we would write inside the class, i.e. 'obj' would be 'self'\n",
    "  from datetime import datetime, timezone\n",
    "  results = {\n",
    "    'time' : f'{datetime.now(timezone.utc)}',\n",
    "    'name' : obj.__class__.__name__,\n",
    "    'id' : hex(id(obj)),\n",
    "    'vars' : [(k,v) for k, v, in vars(obj).items()]\n",
    "  }\n",
    "  return results\n",
    "\n",
    "\n",
    "def debug_class(cls): # This is the decorator\n",
    "  cls.debug = info\n",
    "  return cls \n",
    "\n",
    "\n",
    "# if we want to pass the decorator in function-style:\n",
    "debug_class(Person)\n",
    "# we don't need the function to 'return cls' since we are modifying an object inplace.\n",
    "# However, if we want to use the `@` we need the return, because otherwise, the default return is 'None'.\n",
    "Person = debug_class(Person) \n",
    "# the rhs is returning None and it is assign it to 'Person' that therefore doesn't point anymore to the class Person nor to its decorated version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@debug_class\n",
    "class Person:\n",
    "  def __init__(self, name, age, employed=True):\n",
    "    self.name = name\n",
    "    self.age = age\n",
    "    self.employed = employed\n",
    "\n",
    "p = Person('Giovanni', 32)\n",
    "p.debug()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single Dispatch Generic Functions\n",
    "First lets define what overloading is:\n",
    "\n",
    "`Overloading` in object oriented programming is the ability to create more then a function with the same name al long as its signature is different (essentially if the two functions are distinguishable, i.e. different number/type of arguments etc..). When the program is compiled, the interpreter will understand, based on the signature at which function with the same name we are referring to. \n",
    "\n",
    "In python, since there is no static typing, we can't declare a function signature, therefore, overloading, in its strict sense, is not possible. A workaround to this problem is called  `single dispatch generic function`, which allows us to overload functions based on the type of the first argument (if we want to consider the type of more arguments we need `multi dispatch`).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Application - `Htmlizer`\n",
    "Link to [Single_dispatch_generic_function_Htmlizer](Single_dispatch_generic_function_Htmlizer.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "back to [TOC](#TOC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python optimizations\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interning\n",
    "Python at startup automatically pre-loads (caches) a global list of integer in the range [-5, 256], so these integers have a fixed memory reference. Since these numbers show up often, avoid to reference these each time they appear results in an optimization. A number outside this range will require a new memory reference, and that's why:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 500\n",
    "b = 500\n",
    "a is b # will return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The caches integers are called `Singletons`, basically classes that can be instantiated only once.\n",
    "\n",
    "The same might happen with some strings; python can interning some string (that follow certain rules, letters and numbers concatenated with underscores) in order to speed up the equality (if a string in interned than i can use the `is` operator, otherwise i have to use the `==` character by character). We can force python to interning strings with the sys module:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "usually is something we don't need, unless for example we are working with a large ste of string\n",
    "for NPL and we need to tokenize some words that are reaped often. In this case it can be a useful optimization,\n",
    "since if a string is interned it becomes a Singleton and can be compared with the mush faster 'is' operator.\n",
    "'''\n",
    "import sys\n",
    "\n",
    "a = sys.intern('this will be interned')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Peephole\n",
    "Is an optimization that occur at compile time (so it is repeated each time the script is launched). For example we can have `Constant expression` like numeric calculation thata are better read as the operation rather than the results:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minute_in_day = 60 * 24 # 1440"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The expression `60 * 24` is more readable than `1440` but we may thing that, if the variable is called multiple times, we may have performance issues. This is not the case because this is a constant expression and python knows it, so the first time it encounters the variable stores its results, without having to compute it again.\n",
    "\n",
    "The same happen for membership tests, i.e. check if an object is in a list. If we have a constant expression, python will replace the mutable object with is immutable counterpart (list-> tuples, sets -> fronzensets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "```py\n",
    "for i in range(100000):\n",
    "  if i in [1,2,3]:\n",
    "    pass\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The list `[1,2,3]` is converted into a tuple `(1,2,3)` so that, being immutable, it has a fixed memory address.\n",
    "\n",
    "N.B. sets, since are similar to dictionaries (hashmaps), are much more efficient than lists for membership testing!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "back to [TOC](#TOC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Common Modules\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `string`\n",
    "Module with some useful string constants and representation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `functools`\n",
    "Module with useful functions:\n",
    "\n",
    "* `total_ordering` : decorator for classes that automatically implement comparison functionality (le, ge, lt, gt), if only one of these is already implemented\n",
    "* `reduce`: iterate over a sequence applying a function\n",
    "* `partial`: lets us set some arguments of a function as default parameters\n",
    "* `wraps`: decorator that allow to wrap a function/class metadata and keep it after the decoration\n",
    "* `lru_cache`: decorator that allows caching data in recursive structures\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `itertools`\n",
    "Module with useful iteration methods:\n",
    "* `cycle` create a cyclic iterator from an iterable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `collections`\n",
    "Module with useful functions:\n",
    "\n",
    "* `namedtuple` : tuple with argument assignment - substitute of classes or dictionary in some case\n",
    "* `Counter`: it is a class that takes a list returns a dictionary with the number of occurence of each element in the list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `random`\n",
    "Pseudo random number generator:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `seed` value is required to create a repeatable random sequence (essential for testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(0) # now i can execute thi cell as many time as i want but the output won't change\n",
    "import random\n",
    "for _ in range(3):\n",
    "    print(random.randint(2,10), end=', ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `shuffle` inplace mixing up of a list \n",
    "* `gauss` draw numbers from a gaussian distribution\n",
    "* `choice` draw a random element from a list\n",
    "* `choices` draw a defined number of random element from a list; it has the option to weights the appereance of the elements in the list.\n",
    "* `sample` draw a sample from a list without repetition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `timeit`\n",
    "Platform specific timer for performance evaluation of code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# es. of usage\n",
    "timeit(stmt='math.sqrt(2)', setup='import math', number=n, globals=globals())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `argparser`\n",
    "When we run a python script from terminal it might be useful to be able to pass some arguments/variables that will be used by the script itself. The easiest way to retrieve command arguments is to use the `sys.argv` method which returns a list of strings containing the name of the module runned and the argument passed (arguments must be whitespace-separated).\n",
    "\n",
    "However, the smart way of doing it is to use the builtin module `argparser`:\n",
    "\n",
    "```py\n",
    "import argparse\n",
    "\n",
    "parser = argparse.ArgumentParser(description=\"Description of the parser\")\n",
    "\n",
    "# now we populate the parser with what we expect to retrieve in the command line\n",
    "parser.add_argument('first_arg', help='description of first arg', type=str)\n",
    "parser.add_argument('second_arg', help='description of second arg', type=int)\n",
    "\n",
    "# now we need to tell the parser to parse these arguments from sys.argv[1:] \n",
    "# (by default if nothing specified inside parse_args())\n",
    "args = parser.parse_args()\n",
    "\n",
    "print(args.first_argument)\n",
    "print(args.second_argument)\n",
    "```\n",
    "\n",
    "We can call the module from terminal with the flag `-h` to receive in output the descriptions of the parser, that should help us understand the expected usage of the module\n",
    "\n",
    "We can also specify keyword arguments and many more options:\n",
    "\n",
    "```py\n",
    "parser.add_argument('-kw', '--keyword', help='first kw arg', type=str, required=False, dest='alias name')\n",
    "```\n",
    "\n",
    "where the first two arguments are the short and long way of assign the kw argument in the command line, `required` is to specifuy if the argument is mandatory and `dest` gives an alias to the variable that will be actually used in the code. Other argumnet that we may be interested in are:\n",
    "* `nargs` to accept more value per argument. It can be equal to `+` or `*` depending if we require at least one argument or not \n",
    "* `action` to specify a behavior on the argument like `store_true`, `store_constant` etc..\n",
    "\n",
    "Another useful think is to define a group of mutually exclusive arguments (i.e only one can be specified not both), particularly useful when creating flags:\n",
    "\n",
    "```py\n",
    "group = parser.add_mutually_exclusive_group()\n",
    "group.add_argument('-v', '--verbose', action='store_true')\n",
    "group.add_argument('-q', '--quite', action='store_true')\n",
    "# so doing only one betweee -v and -q can be specified\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "back to [TOC](#TOC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tips and tricks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.version_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exceptions handling\n",
    "\"look before you need\" or \"ask for permission\" are two different approach we can use to catch errors; the first corrispond to try and except, the latter to and if statement. Generally speaking the if statement is faster than the try-except but it may be less expressive; moreover the try-except becomes a burden only if the exception is raised often, otherwise there is not much difference in computational time. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### which import is faster\n",
    "N.B. it matters only if the code is runned a humongus number of time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6948520680016372, 0.4379689560155384)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from timeit import timeit\n",
    "\n",
    "# SLOWER\n",
    "import math\n",
    "\n",
    "# FASTER\n",
    "from math import sqrt\n",
    "\n",
    "n = 10_000_000\n",
    "\n",
    "timeit(stmt='math.sqrt(2)', setup='import math',number=n), timeit(stmt='sqrt(2)', setup='from math import sqrt',number=n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentinel values instead of None\n",
    "Sometimes we need to define function or classe with kw arguments and have a way to check if the user passed thata argument or not. The standard way of proceeding is to set the default value to `None`. This is fine, but sometimes `None` itself can be an acceptable parameter given by the user, but we won't catch it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, None, None)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def some_func(kw=None):\n",
    "    if not kw:\n",
    "        print('kw was not passed')\n",
    "    else:\n",
    "        print('kw was passed')\n",
    "        \n",
    "some_func(), some_func(None), some_func(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, passing `None` as argument result in the wrong behavior (because actually an argument was passed.. it was None!). (btw.  in this case the same goes for any argument that has a truth values of `False`). An alternative approach is tu set a sentinel values as a flag, something so unique that the user could never use it.\n",
    "\n",
    "To do this, a smart idea is to use as sentinel value the `id` of an object since it will be unique in memory. The most genereci way is to use the id of the python object class `id(object()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, None, None, None, None)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_SENTINEL = object()\n",
    "\n",
    "def some_func(kw=_SENTINEL):\n",
    "    if kw is _SENTINEL:\n",
    "        print('kw was not passed')\n",
    "    else:\n",
    "        print('kw was passed')\n",
    "        \n",
    "some_func(), some_func(None), some_func(0), some_func([]), some_func(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, now the behavior is correct and we know exactly if the user has passed an argument. Actually we could have set directly the values of `kw` equal to `object()` since it would have been created at runtime by python when encounter the function definition, thus that object id would have been unique."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Switch statement in python PEP 3103\n",
    "In other programming language, like Java, a switch is a structure that holds different values, and is able to switch from one to the other depending on the key value passed. In python we have different way to simulate this behavior, the simplest (and worst) is with a series of `if, elif` statements, using a dictionary or, more elegantly using an associative array like a single_dispatch_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "back to [TOC](#TOC)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b66e1d652d26545cf719f53d79fc7f17380815b403cf9c9ba2b908f3efa6c6a8"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
